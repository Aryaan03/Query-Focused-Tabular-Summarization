{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0089c5-4b46-4aca-a790-4b2047e05b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61e869e-c882-44ff-8836-b7cdac7a8ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c942905b-8e46-4975-9d9b-4bb5c58552bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from datasets import load_dataset, DatasetDict, Dataset, concatenate_datasets\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from random import sample\n",
    "\n",
    "\n",
    "train_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/question_answered/train_with_answer\")\n",
    "test_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cebf6d67-e4d6-4a27-81e6-a8f0c1c62f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Head coach</th>\n",
       "      <th>Previous job</th>\n",
       "      <th>Year at school</th>\n",
       "      <th>Overall record</th>\n",
       "      <th>MAAC record</th>\n",
       "      <th>MAAC Tournament championships</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canisius</td>\n",
       "      <td>Reggie Witherspoon</td>\n",
       "      <td>Chattanooga (asst.)</td>\n",
       "      <td>3</td>\n",
       "      <td>39–28</td>\n",
       "      <td>25–13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fairfield</td>\n",
       "      <td>Sydney Johnson</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>8</td>\n",
       "      <td>107–125</td>\n",
       "      <td>62–72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iona</td>\n",
       "      <td>Tim Cluess</td>\n",
       "      <td>LIU Post</td>\n",
       "      <td>9</td>\n",
       "      <td>182–92</td>\n",
       "      <td>112–40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Steve Masiello</td>\n",
       "      <td>Louisville (asst.)</td>\n",
       "      <td>8</td>\n",
       "      <td>116–110</td>\n",
       "      <td>72–62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marist</td>\n",
       "      <td>John Dunne</td>\n",
       "      <td>Saint Peter's</td>\n",
       "      <td>1</td>\n",
       "      <td>0–0</td>\n",
       "      <td>0–0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monmouth</td>\n",
       "      <td>King Rice</td>\n",
       "      <td>Vanderbilt (asst.)</td>\n",
       "      <td>8</td>\n",
       "      <td>117–112</td>\n",
       "      <td>60–38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Niagara</td>\n",
       "      <td>Chris Casey</td>\n",
       "      <td>LIU Post</td>\n",
       "      <td>6</td>\n",
       "      <td>51–110</td>\n",
       "      <td>33–65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>Baker Dunleavy</td>\n",
       "      <td>Villanova (asst.)</td>\n",
       "      <td>2</td>\n",
       "      <td>12–21</td>\n",
       "      <td>7–11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rider</td>\n",
       "      <td>Kevin Baggett</td>\n",
       "      <td>Rider (assoc. HC)</td>\n",
       "      <td>7</td>\n",
       "      <td>107–89</td>\n",
       "      <td>69–47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Saint Peter's</td>\n",
       "      <td>Shaheen Holloway</td>\n",
       "      <td>Seton Hall (asst.)</td>\n",
       "      <td>1</td>\n",
       "      <td>0–0</td>\n",
       "      <td>0–0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Siena</td>\n",
       "      <td>Jamion Christian</td>\n",
       "      <td>Mount St. Mary's</td>\n",
       "      <td>1</td>\n",
       "      <td>0–0</td>\n",
       "      <td>0–0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team          Head coach         Previous job Year at school  \\\n",
       "0        Canisius  Reggie Witherspoon  Chattanooga (asst.)              3   \n",
       "1       Fairfield      Sydney Johnson            Princeton              8   \n",
       "2            Iona          Tim Cluess             LIU Post              9   \n",
       "3       Manhattan      Steve Masiello   Louisville (asst.)              8   \n",
       "4          Marist          John Dunne        Saint Peter's              1   \n",
       "5        Monmouth           King Rice   Vanderbilt (asst.)              8   \n",
       "6         Niagara         Chris Casey             LIU Post              6   \n",
       "7      Quinnipiac      Baker Dunleavy    Villanova (asst.)              2   \n",
       "8           Rider       Kevin Baggett    Rider (assoc. HC)              7   \n",
       "9   Saint Peter's    Shaheen Holloway   Seton Hall (asst.)              1   \n",
       "10          Siena    Jamion Christian     Mount St. Mary's              1   \n",
       "\n",
       "   Overall record MAAC record MAAC Tournament championships  \n",
       "0           39–28       25–13                             0  \n",
       "1         107–125       62–72                             0  \n",
       "2          182–92      112–40                             4  \n",
       "3         116–110       72–62                             2  \n",
       "4             0–0         0–0                             1  \n",
       "5         117–112       60–38                             0  \n",
       "6          51–110       33–65                             0  \n",
       "7           12–21        7–11                             0  \n",
       "8          107–89       69–47                             0  \n",
       "9             0–0         0–0                             0  \n",
       "10            0–0         0–0                             0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 1001\n",
    "import pandas as pd\n",
    "def to_pandas(item):\n",
    "  return pd.DataFrame(item['table'][\"rows\"],columns=item['table'][\"header\"])\n",
    "\n",
    "to_pandas(train_df[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dac5063c-c66d-4d55-b560-82c36a09ab69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How many years of experience at their respective school do each of the coaches with MAAC Tournament championships have?',\n",
       " 'COUNT > 9, 8, 1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[ind]['query'], train_df[ind]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0aad3-1299-41c9-ab3c-62f27afd49ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6bd7e-cf43-4f9c-a80d-40f0f64aa618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c52eb3-eb50-427e-8f65-01ec979bb82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_path = \"google/flan-t5-large\"\n",
    "model_path = \"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/models/saved_model/Flan-T5-Decomposed\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e23762-0c6c-4dc7-bb43-89fec8725da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def flatten_table(table: Dict) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    title = table.get('title', [])\n",
    "\n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \"+row_text)\n",
    "\n",
    "    flattened_table = f\"Title: {' '.join(map(str, title))}\" + \" \" + \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "def generate_predictions(dataset):\n",
    "    generated_texts = []\n",
    "    task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "    for example in dataset:\n",
    "        table = example['table']\n",
    "        query = example['query']\n",
    "        flattened_table = flatten_table(table)\n",
    "        input_text = f\"{task_prefix} Table {flattened_table}. Query: {query}\"\n",
    "        model_input = tokenizer(input_text, max_length=1024, truncation=True,padding='max_length') \n",
    "        output_sequences = model.generate(model_input)\n",
    "        generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Add to list of generated text\n",
    "        generated_texts.append(generated_text)\n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a642de-f6b8-4d59-a06f-dfcd237251dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def tokenization_with_answer(examples):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "    for i, (query, table, answer, coordinates, summary) in enumerate(zip(examples['query'], examples['table'], examples['answers'], examples['coordinates'], examples['summary'])):\n",
    "        flattened_table = flatten_table(table, i)\n",
    "        input_text = f\"{task_prefix} Table {flattened_table}. Query: {query}\"\n",
    "\n",
    "        inputs.append(input_text)\n",
    "        targets.append(summary)\n",
    "        \n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True,padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=512, truncation=True)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] \n",
    "\n",
    "    res = tokenizer(inputs, text_target=targets, truncation=True, padding=True)\n",
    "    return model_inputs\n",
    "\n",
    "def flatten_table(table: Dict, row_index: int) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    title = table.get('title', [])\n",
    "\n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \"+row_text)\n",
    "\n",
    "    flattened_table = f\"Title: {' '.join(map(str, title))}\" + \" \" + \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "tokenized_dataset_train = train_df.map(tokenization_with_answer, batched=True)\n",
    "tokenized_dataset_test = test_df.map(tokenization_with_answer, batched=True)\n",
    "\n",
    "processed_data_train = tokenized_dataset_train.remove_columns(['table','summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "processed_data_test = tokenized_dataset_test.remove_columns(['table','summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c362bd54-97f9-4877-971f-9660e059b227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def k_fold_split(dataset, num_folds=5):\n",
    "    fold_size = len(dataset) // num_folds\n",
    "    folds = []\n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if i < num_folds - 1 else len(dataset)\n",
    "        folds.append(dataset.select(range(start, end)))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59e1fb22-0a34-4a52-a0a9-1e34ad0d639b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_predictions, decoded_labels = postprocess_text(decoded_predictions, decoded_labels)\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "\n",
    "    return rouge_results\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model= model)\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./train_weights_flan_decomposed\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    warmup_ratio=0.05,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    overwrite_output_dir= True,\n",
    "    gradient_accumulation_steps = 2\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=processed_data_train,\n",
    "    eval_dataset=processed_data_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=metric_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa45ed-0bf5-4cf7-91bc-72f2a05ac37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:18:03, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.736930</td>\n",
       "      <td>0.310908</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.277832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.674099</td>\n",
       "      <td>0.308910</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.261352</td>\n",
       "      <td>0.274203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.642674</td>\n",
       "      <td>0.307926</td>\n",
       "      <td>0.175376</td>\n",
       "      <td>0.261209</td>\n",
       "      <td>0.276965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>1.627459</td>\n",
       "      <td>0.312875</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.266516</td>\n",
       "      <td>0.281615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>1.609560</td>\n",
       "      <td>0.313811</td>\n",
       "      <td>0.178007</td>\n",
       "      <td>0.266722</td>\n",
       "      <td>0.282186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>1.601541</td>\n",
       "      <td>0.314084</td>\n",
       "      <td>0.180580</td>\n",
       "      <td>0.270219</td>\n",
       "      <td>0.283313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.590100</td>\n",
       "      <td>1.591774</td>\n",
       "      <td>0.314868</td>\n",
       "      <td>0.181450</td>\n",
       "      <td>0.273688</td>\n",
       "      <td>0.285310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.590100</td>\n",
       "      <td>1.589760</td>\n",
       "      <td>0.313330</td>\n",
       "      <td>0.180013</td>\n",
       "      <td>0.271253</td>\n",
       "      <td>0.284016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.590100</td>\n",
       "      <td>1.584818</td>\n",
       "      <td>0.312966</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>0.270743</td>\n",
       "      <td>0.282800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.587157</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>0.180796</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.285048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.587232</td>\n",
       "      <td>0.311752</td>\n",
       "      <td>0.177374</td>\n",
       "      <td>0.270650</td>\n",
       "      <td>0.282907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.583813</td>\n",
       "      <td>0.311862</td>\n",
       "      <td>0.177098</td>\n",
       "      <td>0.269766</td>\n",
       "      <td>0.282433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.584890</td>\n",
       "      <td>0.311941</td>\n",
       "      <td>0.176035</td>\n",
       "      <td>0.269517</td>\n",
       "      <td>0.282297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>1.585590</td>\n",
       "      <td>0.311321</td>\n",
       "      <td>0.174700</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>0.281342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>1.587324</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.175149</td>\n",
       "      <td>0.267721</td>\n",
       "      <td>0.281944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>1.587949</td>\n",
       "      <td>0.311722</td>\n",
       "      <td>0.174046</td>\n",
       "      <td>0.268320</td>\n",
       "      <td>0.280951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.586570</td>\n",
       "      <td>0.311303</td>\n",
       "      <td>0.174212</td>\n",
       "      <td>0.268613</td>\n",
       "      <td>0.279880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.586989</td>\n",
       "      <td>0.311863</td>\n",
       "      <td>0.175364</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>0.280534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.587205</td>\n",
       "      <td>0.309991</td>\n",
       "      <td>0.174278</td>\n",
       "      <td>0.267202</td>\n",
       "      <td>0.279245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.304100</td>\n",
       "      <td>1.587804</td>\n",
       "      <td>0.310150</td>\n",
       "      <td>0.174494</td>\n",
       "      <td>0.267839</td>\n",
       "      <td>0.279813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:07<00:00, 227.05 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 424.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:18:05, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.114217</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.208381</td>\n",
       "      <td>0.291012</td>\n",
       "      <td>0.305302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.118116</td>\n",
       "      <td>0.334085</td>\n",
       "      <td>0.210081</td>\n",
       "      <td>0.293453</td>\n",
       "      <td>0.306973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.118546</td>\n",
       "      <td>0.334477</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.294502</td>\n",
       "      <td>0.308379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>1.120974</td>\n",
       "      <td>0.335667</td>\n",
       "      <td>0.214816</td>\n",
       "      <td>0.294608</td>\n",
       "      <td>0.310219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>1.122085</td>\n",
       "      <td>0.337022</td>\n",
       "      <td>0.214228</td>\n",
       "      <td>0.296231</td>\n",
       "      <td>0.310458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>1.124252</td>\n",
       "      <td>0.335772</td>\n",
       "      <td>0.214457</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>0.310740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.128902</td>\n",
       "      <td>0.335991</td>\n",
       "      <td>0.212867</td>\n",
       "      <td>0.297776</td>\n",
       "      <td>0.311197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.130521</td>\n",
       "      <td>0.335766</td>\n",
       "      <td>0.213879</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>0.309863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.131460</td>\n",
       "      <td>0.333117</td>\n",
       "      <td>0.210617</td>\n",
       "      <td>0.292998</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.136435</td>\n",
       "      <td>0.335629</td>\n",
       "      <td>0.210470</td>\n",
       "      <td>0.295753</td>\n",
       "      <td>0.310432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.140903</td>\n",
       "      <td>0.333916</td>\n",
       "      <td>0.210092</td>\n",
       "      <td>0.294422</td>\n",
       "      <td>0.308496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.142368</td>\n",
       "      <td>0.333691</td>\n",
       "      <td>0.208403</td>\n",
       "      <td>0.292873</td>\n",
       "      <td>0.307699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.141692</td>\n",
       "      <td>0.331785</td>\n",
       "      <td>0.208415</td>\n",
       "      <td>0.291990</td>\n",
       "      <td>0.305413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.057500</td>\n",
       "      <td>1.143903</td>\n",
       "      <td>0.332044</td>\n",
       "      <td>0.208861</td>\n",
       "      <td>0.291732</td>\n",
       "      <td>0.306444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.057500</td>\n",
       "      <td>1.145598</td>\n",
       "      <td>0.328937</td>\n",
       "      <td>0.207119</td>\n",
       "      <td>0.289114</td>\n",
       "      <td>0.303122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.057500</td>\n",
       "      <td>1.149624</td>\n",
       "      <td>0.329204</td>\n",
       "      <td>0.206698</td>\n",
       "      <td>0.289056</td>\n",
       "      <td>0.303638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.150244</td>\n",
       "      <td>0.328386</td>\n",
       "      <td>0.205993</td>\n",
       "      <td>0.289052</td>\n",
       "      <td>0.303846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.152382</td>\n",
       "      <td>0.331026</td>\n",
       "      <td>0.205888</td>\n",
       "      <td>0.289028</td>\n",
       "      <td>0.304807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.152307</td>\n",
       "      <td>0.332553</td>\n",
       "      <td>0.205090</td>\n",
       "      <td>0.289466</td>\n",
       "      <td>0.305587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.000300</td>\n",
       "      <td>1.152647</td>\n",
       "      <td>0.331864</td>\n",
       "      <td>0.205897</td>\n",
       "      <td>0.289532</td>\n",
       "      <td>0.305336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:07<00:00, 248.24 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 418.82 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:20:11, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.356044</td>\n",
       "      <td>0.254560</td>\n",
       "      <td>0.325054</td>\n",
       "      <td>0.337029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.744739</td>\n",
       "      <td>0.350753</td>\n",
       "      <td>0.248350</td>\n",
       "      <td>0.320862</td>\n",
       "      <td>0.331651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.748812</td>\n",
       "      <td>0.349803</td>\n",
       "      <td>0.247885</td>\n",
       "      <td>0.318771</td>\n",
       "      <td>0.331270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>0.753681</td>\n",
       "      <td>0.350841</td>\n",
       "      <td>0.251319</td>\n",
       "      <td>0.320557</td>\n",
       "      <td>0.332555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>0.753704</td>\n",
       "      <td>0.347714</td>\n",
       "      <td>0.246035</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.328965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>0.759392</td>\n",
       "      <td>0.347544</td>\n",
       "      <td>0.245990</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.329383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.760708</td>\n",
       "      <td>0.344649</td>\n",
       "      <td>0.243347</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>0.325964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.763665</td>\n",
       "      <td>0.344218</td>\n",
       "      <td>0.241890</td>\n",
       "      <td>0.312875</td>\n",
       "      <td>0.326514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.342378</td>\n",
       "      <td>0.239609</td>\n",
       "      <td>0.311347</td>\n",
       "      <td>0.325060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.768537</td>\n",
       "      <td>0.347525</td>\n",
       "      <td>0.248661</td>\n",
       "      <td>0.316489</td>\n",
       "      <td>0.330389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.774045</td>\n",
       "      <td>0.343487</td>\n",
       "      <td>0.240955</td>\n",
       "      <td>0.310064</td>\n",
       "      <td>0.324798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.772051</td>\n",
       "      <td>0.345042</td>\n",
       "      <td>0.242849</td>\n",
       "      <td>0.311217</td>\n",
       "      <td>0.325569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.775958</td>\n",
       "      <td>0.344153</td>\n",
       "      <td>0.242541</td>\n",
       "      <td>0.311678</td>\n",
       "      <td>0.326097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.778448</td>\n",
       "      <td>0.343593</td>\n",
       "      <td>0.245498</td>\n",
       "      <td>0.313192</td>\n",
       "      <td>0.327429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.779775</td>\n",
       "      <td>0.345764</td>\n",
       "      <td>0.246139</td>\n",
       "      <td>0.314098</td>\n",
       "      <td>0.327797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.783263</td>\n",
       "      <td>0.341986</td>\n",
       "      <td>0.241788</td>\n",
       "      <td>0.311150</td>\n",
       "      <td>0.326038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.783553</td>\n",
       "      <td>0.345198</td>\n",
       "      <td>0.243698</td>\n",
       "      <td>0.312431</td>\n",
       "      <td>0.327195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.784037</td>\n",
       "      <td>0.343836</td>\n",
       "      <td>0.242943</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.326626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.784538</td>\n",
       "      <td>0.342158</td>\n",
       "      <td>0.240813</td>\n",
       "      <td>0.310456</td>\n",
       "      <td>0.325264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.784281</td>\n",
       "      <td>0.344187</td>\n",
       "      <td>0.244014</td>\n",
       "      <td>0.312351</td>\n",
       "      <td>0.327971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:06<00:00, 267.77 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 399.74 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:26:43, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508371</td>\n",
       "      <td>0.354669</td>\n",
       "      <td>0.266144</td>\n",
       "      <td>0.330871</td>\n",
       "      <td>0.341029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508990</td>\n",
       "      <td>0.356684</td>\n",
       "      <td>0.272199</td>\n",
       "      <td>0.334627</td>\n",
       "      <td>0.345068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.514289</td>\n",
       "      <td>0.357115</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.333715</td>\n",
       "      <td>0.344960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.516900</td>\n",
       "      <td>0.358190</td>\n",
       "      <td>0.270751</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>0.345776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.520137</td>\n",
       "      <td>0.355598</td>\n",
       "      <td>0.265978</td>\n",
       "      <td>0.331804</td>\n",
       "      <td>0.342417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.522712</td>\n",
       "      <td>0.354043</td>\n",
       "      <td>0.266569</td>\n",
       "      <td>0.331453</td>\n",
       "      <td>0.341544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.524508</td>\n",
       "      <td>0.355427</td>\n",
       "      <td>0.265465</td>\n",
       "      <td>0.330176</td>\n",
       "      <td>0.342221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.527906</td>\n",
       "      <td>0.352531</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.328863</td>\n",
       "      <td>0.339307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>0.350817</td>\n",
       "      <td>0.260793</td>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.338545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.530158</td>\n",
       "      <td>0.352120</td>\n",
       "      <td>0.260756</td>\n",
       "      <td>0.326480</td>\n",
       "      <td>0.338567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.531662</td>\n",
       "      <td>0.351079</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>0.326272</td>\n",
       "      <td>0.338009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.532701</td>\n",
       "      <td>0.350051</td>\n",
       "      <td>0.257891</td>\n",
       "      <td>0.323277</td>\n",
       "      <td>0.335481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.533766</td>\n",
       "      <td>0.349917</td>\n",
       "      <td>0.259230</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>0.336174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.536118</td>\n",
       "      <td>0.349070</td>\n",
       "      <td>0.258604</td>\n",
       "      <td>0.325435</td>\n",
       "      <td>0.336151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.535038</td>\n",
       "      <td>0.349867</td>\n",
       "      <td>0.258945</td>\n",
       "      <td>0.324671</td>\n",
       "      <td>0.336255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.535661</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>0.261125</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.337182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.537804</td>\n",
       "      <td>0.350260</td>\n",
       "      <td>0.258777</td>\n",
       "      <td>0.325861</td>\n",
       "      <td>0.336627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.537542</td>\n",
       "      <td>0.348839</td>\n",
       "      <td>0.258032</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>0.335708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.538087</td>\n",
       "      <td>0.349555</td>\n",
       "      <td>0.258964</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.337129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.537727</td>\n",
       "      <td>0.350019</td>\n",
       "      <td>0.259268</td>\n",
       "      <td>0.325442</td>\n",
       "      <td>0.337476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:08<00:00, 213.65 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 386.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 151/3000 03:29 < 1:06:48, 0.71 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = k_fold_split(train_df, num_folds=10)\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    val_fold = folds[i]\n",
    "    train_folds = [folds[j] for j in range(len(folds)) if j != i]\n",
    "    train_dataset = concatenate_datasets(train_folds)\n",
    "\n",
    "    tokenized_train = train_dataset.map(tokenization_with_answer, batched=True)\n",
    "    tokenized_val = val_fold.map(tokenization_with_answer, batched=True)\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    processed_train = tokenized_train.remove_columns(['table', 'summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "    processed_val = tokenized_val.remove_columns(['table', 'summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "\n",
    "    # Update your trainer's train_dataset and eval_dataset\n",
    "    trainer.train_dataset = processed_train\n",
    "    trainer.eval_dataset = processed_val\n",
    "\n",
    "    # Train your model\n",
    "    trainer.train()\n",
    "    trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a989eb-3114-4a88-93ed-f67038ce9956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"Flan-decomposed\")\n",
    "tokenizer.save_pretrained(\"Flan-decomposed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4648d-9f45-4f83-932a-612a13942e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493dda4b-09a4-4367-b302-13ea039818fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8732d7b-54cd-402f-a124-7071c2bea17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ce1bc1-ef8e-45d8-86e8-158ac78c215a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 11:10:35.274337: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 11:11:05.976143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:/opt/slurm/lib64:\n",
      "2024-04-05 11:11:05.976185: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-05 11:11:09.368485: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-05 11:11:19.948793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:/opt/slurm/lib64:\n",
      "2024-04-05 11:11:19.949125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:/opt/slurm/lib64:\n",
      "2024-04-05 11:11:19.949133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from datasets import load_dataset, DatasetDict, Dataset, concatenate_datasets\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "from random import sample\n",
    "\n",
    "\n",
    "train_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_train\")\n",
    "test_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cf9ce2-0742-43ac-b24d-d049e3dc906d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/models/saved_model/Flan-T5-Decomposed\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0550c6-3a94-45c9-9ddf-246e89f86b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def tokenization_with_answer(examples):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "    for i, (query, table, answer, coordinates, summary) in enumerate(zip(examples['query'], examples['table'], examples['answers'], examples['coordinates'], examples['summary'])):\n",
    "        flattened_table = flatten_table(table, i)\n",
    "        input_text = f\"{task_prefix} Table {flattened_table}. Query: {query}\"\n",
    "\n",
    "        inputs.append(input_text)\n",
    "        targets.append(summary)\n",
    "        \n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True,padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=512, truncation=True)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] \n",
    "\n",
    "    res = tokenizer(inputs, text_target=targets, truncation=True, padding=True)\n",
    "    return model_inputs\n",
    "\n",
    "def flatten_table(table: Dict, row_index: int) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    title = table.get('title', [])\n",
    "\n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \"+row_text)\n",
    "\n",
    "    flattened_table = f\"Title: {' '.join(map(str, title))}\" + \" \" + \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "tokenized_dataset_train = train_df.map(tokenization_with_answer, batched=True)\n",
    "tokenized_dataset_test = test_df.map(tokenization_with_answer, batched=True)\n",
    "\n",
    "processed_data_train = tokenized_dataset_train.remove_columns(['table','summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "processed_data_test = tokenized_dataset_test.remove_columns(['table','summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_predictions, decoded_labels = postprocess_text(decoded_predictions, decoded_labels)\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "\n",
    "    return rouge_results\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model= model)\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./train_weights_flan_decomposed\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    warmup_ratio=0.05,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    overwrite_output_dir= True,\n",
    "    gradient_accumulation_steps = 2\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=processed_data_train,\n",
    "    eval_dataset=processed_data_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=metric_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f6f2d1-c2e4-4465-b300-b43f0c2ce94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validate_df_size = len(validate_df)\n",
    "step_size = 3\n",
    "num_batches = validate_df_size // step_size\n",
    "\n",
    "valid = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_index = i * step_size\n",
    "    end_index = (i + 1) * step_size\n",
    "    valid.append(validate_df.select(range(start_index, end_index)))\n",
    "\n",
    "# If there are remaining data points that don't fit into full batches of size 3\n",
    "if validate_df_size % step_size != 0:\n",
    "    remaining_data = validate_df_size % step_size\n",
    "    valid.append(validate_df.select(range(validate_df_size - remaining_data, validate_df_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360c0b6d-4018-45d3-ac03-a9c138fdab67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3/3 [00:00<00:00,  3.54 examples/s]\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.40658831946919716, 0.8971968287259189)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rougeL = []\n",
    "bert = []\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "for i in range(len(valid)):\n",
    "    validate_df = valid[i].map(tokenization_with_answer, batched=True)\n",
    "    predict_results = trainer.predict(validate_df, max_length = 1024)\n",
    "    metrics = predict_results.metrics\n",
    "    predictions = tokenizer.batch_decode(predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    predictions = [pred.strip() for pred in predictions]\n",
    "    \n",
    "    bert_score = bertscore.compute(predictions=predictions, references=valid[i]['summary'], lang = \"en\")\n",
    "    rougeL.append(metrics['test_rougeLsum'])\n",
    "    bert.append(np.mean(bert_score['f1']))\n",
    "\n",
    "sum(rougeL)/len(rougeL), sum(bert)/len(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c84c9f-5f21-407d-99d8-a043375fdf49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa2fc4-d7f4-4ae0-8bd5-9ff30d00c54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a52bfcbd-c40b-4ff1-a67d-76f91f9f6d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46537140837246876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df = valid[16].map(tokenization_with_answer, batched=True)\n",
    "predict_results = trainer.predict(validate_df, max_length = 1024)\n",
    "metrics = predict_results.metrics\n",
    "metrics['test_rougeLsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b04976a2-0b09-48f8-9b15-87fdbd330fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Based on the table, the yearly trend in the total number of acres affected by the wildfires in California has been upwards. The earliest fire started in 1932, the San Andreas fire, burned a total of 220,000 acres in Sonoma County, while the newest fire started in 2017, destroyed 281,893 acres in Sonoma County. The smallest fire, the El Dorado fire, started in Kern County in December 2017, destroyed 257,314 acres in Sonoma County.',\n",
       " 'The chronological order of episodes in Columbo\\'s fourth season is as follows: Episode 1 is \"An Exercise in Fatality,\" episode 2 is \"Negative Reaction,\" episode 3 is \"By Dawn\\'s Early Light,\" episode 4 is \"Troubled Waters,\" episode 5 is \"Playback,\" episode 6 is \"A Deadly State of Mind.\" The murderers and victims for these episodes are Robert Conrad, Dick Van Dyke, Patrick McGoohan, Robert Vaughn, Oskar Werner, and George Hamilton.',\n",
       " 'The players who played for the Utah Jazz and attended Byu are Andy Toolson, who played for the Jazz from 1990-91 and 1995-96. Andy Toolson was a forward who played for the Jazz from 1990-91 and 1995-96.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tokenizer.batch_decode(predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "predictions = [pred.strip() for pred in predictions]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b2c2b9-09ac-499b-b7df-2ff5e225d179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are not enough datas to make a sure conclusion about yearly trend of total acres affected by wildfires in California. As this table only has biggest wildfires and not all fires in state, it cannot show the full trend of every year. However, we can see that some more new fires, like Mendocino Complex in 2018 and Thomas Fire in 2017, have very big acreage. This may show that there is a going up trend in how bad wildfires are in recent years.',\n",
       " 'In fourth season of Columbo, first episode is \"An Exercise in Fatality\" on September 15, 1974. Have murderer Robert Conrad and victim Philip Bruns. Second episode is \"Negative Reaction\" on October 6, 1974. Have Dick Van Dyke as murderer and Antoinette Bower and Don Gordon as victims. Other episodes in order are: \"By Dawn\\'s Early Light\" with Patrick McGoohan as murderer and Tom Simcox as victim, \"Troubled Waters\" have Robert Vaughn as murderer and Poupée Bocar as victim, \"Playback\" with Oskar Werner as murderer and Martha Scott as victim, and last \"A Deadly State of Mind\" have George Hamilton as murderer and Stephen Elliott and Lesley Ann Warren as victims.',\n",
       " 'The players who attended Byu and played for the Utah Jazz are Andy Toolson. Toolson first played for the Jazz from 1990-91 and then again from 1995-96. He was a guard and forward and had the jersey number 5.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423d957e-eee4-49ff-b065-b48cdfda8a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41896ff2-9dbc-48a1-9992-7de0489a517c'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[47][1]['example_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93697305-2bf2-40c8-8289-e18d4e4afd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab-llm",
   "language": "python",
   "name": "tab-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
