{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0089c5-4b46-4aca-a790-4b2047e05b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61e869e-c882-44ff-8836-b7cdac7a8ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c942905b-8e46-4975-9d9b-4bb5c58552bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from datasets import load_dataset, DatasetDict, Dataset, concatenate_datasets\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from random import sample\n",
    "\n",
    "\n",
    "train_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_train\")\n",
    "test_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = datasets.load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c52eb3-eb50-427e-8f65-01ec979bb82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a642de-f6b8-4d59-a06f-dfcd237251dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def tokenization_with_answer(examples):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "    for i, (query, table, answer, coordinates, summary) in enumerate(zip(examples['query'], examples['table'], examples['answers'], examples['coordinates'], examples['summary'])):\n",
    "        flattened_table = flatten_table(table, i)\n",
    "        input_text = f\"{task_prefix} Table {flattened_table}. Query: {query}\"\n",
    "\n",
    "        inputs.append(input_text)\n",
    "        targets.append(summary)\n",
    "        \n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True,padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=512, truncation=True)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] \n",
    "\n",
    "    res = tokenizer(inputs, text_target=targets, truncation=True, padding=True)\n",
    "    return model_inputs\n",
    "\n",
    "def flatten_table(table: Dict, row_index: int) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    title = table.get('title', [])\n",
    "\n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \"+row_text)\n",
    "\n",
    "    flattened_table = f\"Title: {' '.join(map(str, title))}\" + \" \" + \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "tokenized_dataset_train = train_df.map(tokenization_with_answer, batched=True)\n",
    "tokenized_dataset_test = test_df.map(tokenization_with_answer, batched=True)\n",
    "\n",
    "processed_data_train = tokenized_dataset_train.remove_columns(['table','summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "processed_data_test = tokenized_dataset_test.remove_columns(['table','summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c362bd54-97f9-4877-971f-9660e059b227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def k_fold_split(dataset, num_folds=5):\n",
    "    fold_size = len(dataset) // num_folds\n",
    "    folds = []\n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if i < num_folds - 1 else len(dataset)\n",
    "        folds.append(dataset.select(range(start, end)))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e1fb22-0a34-4a52-a0a9-1e34ad0d639b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 13:23:02.869744: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 13:23:07.460485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_predictions, decoded_labels = postprocess_text(decoded_predictions, decoded_labels)\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "\n",
    "    return rouge_results\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model= model)\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./train_weights_bart\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=5,\n",
    "    warmup_ratio=0.03,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True,\n",
    "    overwrite_output_dir= True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=processed_data_train,\n",
    "    eval_dataset=processed_data_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=metric_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa45ed-0bf5-4cf7-91bc-72f2a05ac37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:18:03, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.736930</td>\n",
       "      <td>0.310908</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.277832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.674099</td>\n",
       "      <td>0.308910</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.261352</td>\n",
       "      <td>0.274203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.642674</td>\n",
       "      <td>0.307926</td>\n",
       "      <td>0.175376</td>\n",
       "      <td>0.261209</td>\n",
       "      <td>0.276965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>1.627459</td>\n",
       "      <td>0.312875</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.266516</td>\n",
       "      <td>0.281615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>1.609560</td>\n",
       "      <td>0.313811</td>\n",
       "      <td>0.178007</td>\n",
       "      <td>0.266722</td>\n",
       "      <td>0.282186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.834600</td>\n",
       "      <td>1.601541</td>\n",
       "      <td>0.314084</td>\n",
       "      <td>0.180580</td>\n",
       "      <td>0.270219</td>\n",
       "      <td>0.283313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.590100</td>\n",
       "      <td>1.591774</td>\n",
       "      <td>0.314868</td>\n",
       "      <td>0.181450</td>\n",
       "      <td>0.273688</td>\n",
       "      <td>0.285310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.590100</td>\n",
       "      <td>1.589760</td>\n",
       "      <td>0.313330</td>\n",
       "      <td>0.180013</td>\n",
       "      <td>0.271253</td>\n",
       "      <td>0.284016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.590100</td>\n",
       "      <td>1.584818</td>\n",
       "      <td>0.312966</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>0.270743</td>\n",
       "      <td>0.282800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.587157</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>0.180796</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.285048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.587232</td>\n",
       "      <td>0.311752</td>\n",
       "      <td>0.177374</td>\n",
       "      <td>0.270650</td>\n",
       "      <td>0.282907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.583813</td>\n",
       "      <td>0.311862</td>\n",
       "      <td>0.177098</td>\n",
       "      <td>0.269766</td>\n",
       "      <td>0.282433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.584890</td>\n",
       "      <td>0.311941</td>\n",
       "      <td>0.176035</td>\n",
       "      <td>0.269517</td>\n",
       "      <td>0.282297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>1.585590</td>\n",
       "      <td>0.311321</td>\n",
       "      <td>0.174700</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>0.281342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>1.587324</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.175149</td>\n",
       "      <td>0.267721</td>\n",
       "      <td>0.281944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.382100</td>\n",
       "      <td>1.587949</td>\n",
       "      <td>0.311722</td>\n",
       "      <td>0.174046</td>\n",
       "      <td>0.268320</td>\n",
       "      <td>0.280951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.586570</td>\n",
       "      <td>0.311303</td>\n",
       "      <td>0.174212</td>\n",
       "      <td>0.268613</td>\n",
       "      <td>0.279880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.586989</td>\n",
       "      <td>0.311863</td>\n",
       "      <td>0.175364</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>0.280534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>1.587205</td>\n",
       "      <td>0.309991</td>\n",
       "      <td>0.174278</td>\n",
       "      <td>0.267202</td>\n",
       "      <td>0.279245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.304100</td>\n",
       "      <td>1.587804</td>\n",
       "      <td>0.310150</td>\n",
       "      <td>0.174494</td>\n",
       "      <td>0.267839</td>\n",
       "      <td>0.279813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:07<00:00, 227.05 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 424.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:18:05, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.114217</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.208381</td>\n",
       "      <td>0.291012</td>\n",
       "      <td>0.305302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.118116</td>\n",
       "      <td>0.334085</td>\n",
       "      <td>0.210081</td>\n",
       "      <td>0.293453</td>\n",
       "      <td>0.306973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.118546</td>\n",
       "      <td>0.334477</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.294502</td>\n",
       "      <td>0.308379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>1.120974</td>\n",
       "      <td>0.335667</td>\n",
       "      <td>0.214816</td>\n",
       "      <td>0.294608</td>\n",
       "      <td>0.310219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>1.122085</td>\n",
       "      <td>0.337022</td>\n",
       "      <td>0.214228</td>\n",
       "      <td>0.296231</td>\n",
       "      <td>0.310458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>1.124252</td>\n",
       "      <td>0.335772</td>\n",
       "      <td>0.214457</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>0.310740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.128902</td>\n",
       "      <td>0.335991</td>\n",
       "      <td>0.212867</td>\n",
       "      <td>0.297776</td>\n",
       "      <td>0.311197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.130521</td>\n",
       "      <td>0.335766</td>\n",
       "      <td>0.213879</td>\n",
       "      <td>0.296524</td>\n",
       "      <td>0.309863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.191400</td>\n",
       "      <td>1.131460</td>\n",
       "      <td>0.333117</td>\n",
       "      <td>0.210617</td>\n",
       "      <td>0.292998</td>\n",
       "      <td>0.307099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.136435</td>\n",
       "      <td>0.335629</td>\n",
       "      <td>0.210470</td>\n",
       "      <td>0.295753</td>\n",
       "      <td>0.310432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.140903</td>\n",
       "      <td>0.333916</td>\n",
       "      <td>0.210092</td>\n",
       "      <td>0.294422</td>\n",
       "      <td>0.308496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.142368</td>\n",
       "      <td>0.333691</td>\n",
       "      <td>0.208403</td>\n",
       "      <td>0.292873</td>\n",
       "      <td>0.307699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.119400</td>\n",
       "      <td>1.141692</td>\n",
       "      <td>0.331785</td>\n",
       "      <td>0.208415</td>\n",
       "      <td>0.291990</td>\n",
       "      <td>0.305413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.057500</td>\n",
       "      <td>1.143903</td>\n",
       "      <td>0.332044</td>\n",
       "      <td>0.208861</td>\n",
       "      <td>0.291732</td>\n",
       "      <td>0.306444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.057500</td>\n",
       "      <td>1.145598</td>\n",
       "      <td>0.328937</td>\n",
       "      <td>0.207119</td>\n",
       "      <td>0.289114</td>\n",
       "      <td>0.303122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.057500</td>\n",
       "      <td>1.149624</td>\n",
       "      <td>0.329204</td>\n",
       "      <td>0.206698</td>\n",
       "      <td>0.289056</td>\n",
       "      <td>0.303638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.150244</td>\n",
       "      <td>0.328386</td>\n",
       "      <td>0.205993</td>\n",
       "      <td>0.289052</td>\n",
       "      <td>0.303846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.152382</td>\n",
       "      <td>0.331026</td>\n",
       "      <td>0.205888</td>\n",
       "      <td>0.289028</td>\n",
       "      <td>0.304807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.152307</td>\n",
       "      <td>0.332553</td>\n",
       "      <td>0.205090</td>\n",
       "      <td>0.289466</td>\n",
       "      <td>0.305587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.000300</td>\n",
       "      <td>1.152647</td>\n",
       "      <td>0.331864</td>\n",
       "      <td>0.205897</td>\n",
       "      <td>0.289532</td>\n",
       "      <td>0.305336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:07<00:00, 248.24 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 418.82 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:20:11, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.356044</td>\n",
       "      <td>0.254560</td>\n",
       "      <td>0.325054</td>\n",
       "      <td>0.337029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.744739</td>\n",
       "      <td>0.350753</td>\n",
       "      <td>0.248350</td>\n",
       "      <td>0.320862</td>\n",
       "      <td>0.331651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.748812</td>\n",
       "      <td>0.349803</td>\n",
       "      <td>0.247885</td>\n",
       "      <td>0.318771</td>\n",
       "      <td>0.331270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>0.753681</td>\n",
       "      <td>0.350841</td>\n",
       "      <td>0.251319</td>\n",
       "      <td>0.320557</td>\n",
       "      <td>0.332555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>0.753704</td>\n",
       "      <td>0.347714</td>\n",
       "      <td>0.246035</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.328965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>0.759392</td>\n",
       "      <td>0.347544</td>\n",
       "      <td>0.245990</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.329383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.760708</td>\n",
       "      <td>0.344649</td>\n",
       "      <td>0.243347</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>0.325964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.763665</td>\n",
       "      <td>0.344218</td>\n",
       "      <td>0.241890</td>\n",
       "      <td>0.312875</td>\n",
       "      <td>0.326514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.342378</td>\n",
       "      <td>0.239609</td>\n",
       "      <td>0.311347</td>\n",
       "      <td>0.325060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.768537</td>\n",
       "      <td>0.347525</td>\n",
       "      <td>0.248661</td>\n",
       "      <td>0.316489</td>\n",
       "      <td>0.330389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.774045</td>\n",
       "      <td>0.343487</td>\n",
       "      <td>0.240955</td>\n",
       "      <td>0.310064</td>\n",
       "      <td>0.324798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.772051</td>\n",
       "      <td>0.345042</td>\n",
       "      <td>0.242849</td>\n",
       "      <td>0.311217</td>\n",
       "      <td>0.325569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.775958</td>\n",
       "      <td>0.344153</td>\n",
       "      <td>0.242541</td>\n",
       "      <td>0.311678</td>\n",
       "      <td>0.326097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.778448</td>\n",
       "      <td>0.343593</td>\n",
       "      <td>0.245498</td>\n",
       "      <td>0.313192</td>\n",
       "      <td>0.327429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.779775</td>\n",
       "      <td>0.345764</td>\n",
       "      <td>0.246139</td>\n",
       "      <td>0.314098</td>\n",
       "      <td>0.327797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.783263</td>\n",
       "      <td>0.341986</td>\n",
       "      <td>0.241788</td>\n",
       "      <td>0.311150</td>\n",
       "      <td>0.326038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.783553</td>\n",
       "      <td>0.345198</td>\n",
       "      <td>0.243698</td>\n",
       "      <td>0.312431</td>\n",
       "      <td>0.327195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.784037</td>\n",
       "      <td>0.343836</td>\n",
       "      <td>0.242943</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.326626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.784538</td>\n",
       "      <td>0.342158</td>\n",
       "      <td>0.240813</td>\n",
       "      <td>0.310456</td>\n",
       "      <td>0.325264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.784281</td>\n",
       "      <td>0.344187</td>\n",
       "      <td>0.244014</td>\n",
       "      <td>0.312351</td>\n",
       "      <td>0.327971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:06<00:00, 267.77 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 399.74 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 1:26:43, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508371</td>\n",
       "      <td>0.354669</td>\n",
       "      <td>0.266144</td>\n",
       "      <td>0.330871</td>\n",
       "      <td>0.341029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508990</td>\n",
       "      <td>0.356684</td>\n",
       "      <td>0.272199</td>\n",
       "      <td>0.334627</td>\n",
       "      <td>0.345068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.514289</td>\n",
       "      <td>0.357115</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.333715</td>\n",
       "      <td>0.344960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.516900</td>\n",
       "      <td>0.358190</td>\n",
       "      <td>0.270751</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>0.345776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.520137</td>\n",
       "      <td>0.355598</td>\n",
       "      <td>0.265978</td>\n",
       "      <td>0.331804</td>\n",
       "      <td>0.342417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.522712</td>\n",
       "      <td>0.354043</td>\n",
       "      <td>0.266569</td>\n",
       "      <td>0.331453</td>\n",
       "      <td>0.341544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.524508</td>\n",
       "      <td>0.355427</td>\n",
       "      <td>0.265465</td>\n",
       "      <td>0.330176</td>\n",
       "      <td>0.342221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.527906</td>\n",
       "      <td>0.352531</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.328863</td>\n",
       "      <td>0.339307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>0.350817</td>\n",
       "      <td>0.260793</td>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.338545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.530158</td>\n",
       "      <td>0.352120</td>\n",
       "      <td>0.260756</td>\n",
       "      <td>0.326480</td>\n",
       "      <td>0.338567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.531662</td>\n",
       "      <td>0.351079</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>0.326272</td>\n",
       "      <td>0.338009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.532701</td>\n",
       "      <td>0.350051</td>\n",
       "      <td>0.257891</td>\n",
       "      <td>0.323277</td>\n",
       "      <td>0.335481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.533766</td>\n",
       "      <td>0.349917</td>\n",
       "      <td>0.259230</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>0.336174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.536118</td>\n",
       "      <td>0.349070</td>\n",
       "      <td>0.258604</td>\n",
       "      <td>0.325435</td>\n",
       "      <td>0.336151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.535038</td>\n",
       "      <td>0.349867</td>\n",
       "      <td>0.258945</td>\n",
       "      <td>0.324671</td>\n",
       "      <td>0.336255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.535661</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>0.261125</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.337182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.537804</td>\n",
       "      <td>0.350260</td>\n",
       "      <td>0.258777</td>\n",
       "      <td>0.325861</td>\n",
       "      <td>0.336627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.537542</td>\n",
       "      <td>0.348839</td>\n",
       "      <td>0.258032</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>0.335708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.538087</td>\n",
       "      <td>0.349555</td>\n",
       "      <td>0.258964</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.337129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.537727</td>\n",
       "      <td>0.350019</td>\n",
       "      <td>0.259268</td>\n",
       "      <td>0.325442</td>\n",
       "      <td>0.337476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 04:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1800/1800 [00:08<00:00, 213.65 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 386.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 151/3000 03:29 < 1:06:48, 0.71 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = k_fold_split(train_df, num_folds=10)\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    val_fold = folds[i]\n",
    "    train_folds = [folds[j] for j in range(len(folds)) if j != i]\n",
    "    train_dataset = concatenate_datasets(train_folds)\n",
    "\n",
    "    tokenized_train = train_dataset.map(tokenization_with_answer, batched=True)\n",
    "    tokenized_val = val_fold.map(tokenization_with_answer, batched=True)\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    processed_train = tokenized_train.remove_columns(['table', 'summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "    processed_val = tokenized_val.remove_columns(['table', 'summary', 'row_ids', 'example_id', 'query', 'answers', 'coordinates'])\n",
    "\n",
    "    # Update your trainer's train_dataset and eval_dataset\n",
    "    trainer.train_dataset = processed_train\n",
    "    trainer.eval_dataset = processed_val\n",
    "\n",
    "    # Train your model\n",
    "    trainer.train()\n",
    "    trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a989eb-3114-4a88-93ed-f67038ce9956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"Flan-descomposed\")\n",
    "tokenizer.save_pretrained(\"Flan-decomposed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6477e51-987a-4b58-84b1-52125bf6459f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
