{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd762866-8077-4804-b041-70a8bde5586b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import torch \n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d51b4ab-15f6-45a8-996e-5998785170f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    ")\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "from typing import List, Dict\n",
    "\n",
    "train_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_train\")\n",
    "test_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f45f4650-5af7-4059-93b8-9c6652bab629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_table(table: Dict) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    \n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \" + row_text)\n",
    "\n",
    "    flattened_table = \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "def generate_validate_prompt(examples):\n",
    "    table = examples['table']\n",
    "    query = examples['query']\n",
    "    summary = examples['summary']\n",
    "    table_title = table['title']\n",
    "    system_prompt = \"You are a helpful, respectful and honest assistant. Below is an instruction that describes a query-focused table summarization task. Write a summary that appropriately response to the user query.\"\n",
    "    \n",
    "    task = \"Using the information from the table, generate a paragraph-long summary to response to the following user query:\"\n",
    "\n",
    "    \n",
    "    flattened_table = flatten_table(table)\n",
    "    input_text = f\"Table Title: {table_title}\\n{flattened_table}\\n{task}\\nQuery: {query}\\n\\nSummary:\\n\"\n",
    "    prompt = f'<s> [INST] {system_prompt}\\nTable Title: {table_title}\\n{flattened_table}\\n{task} [/INST]\\nUser: {query}\\nAssistant: \"Summary\": '\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52dbe26d-7dc9-45bf-9999-8d7a92233607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] You are a helpful, respectful and honest assistant. Below is an instruction that describes a query-focused table summarization task. Write a summary that appropriately response to the user query.\n",
      "Table Title: Swiss Locomotive And Machine Works\n",
      "## Row 0, Built:1895,Number:1,Type:Mountain Railway Rack Steam Locomotive,Slm Number:923,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 1, Built:1895,Number:2,Type:Mountain Railway Rack Steam Locomotive,Slm Number:924,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 2, Built:1895,Number:3,Type:Mountain Railway Rack Steam Locomotive,Slm Number:925,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 3, Built:1896,Number:4,Type:Mountain Railway Rack Steam Locomotive,Slm Number:988,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 4, Built:1896,Number:5,Type:Mountain Railway Rack Steam Locomotive,Slm Number:989,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 5, Built:1922,Number:6,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2838,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 6, Built:1923,Number:7,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2869,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 7, Built:1923,Number:8,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2870,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway\n",
      "Using the information from the table, generate a paragraph-long summary to response to the following user query: [/INST]\n",
      "User: Summarize the basic information of the locomotive(s) built by Swiss Locomotive and Machine Works with slm number 988.\n",
      "Assistant: \"Summary\": \n"
     ]
    }
   ],
   "source": [
    "prompt = generate_validate_prompt(validate_df[1])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbba0df2-25e2-4b16-a703-c6cb98bc400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 59/59 [10:57<00:00, 11.15s/it]\n",
      "generation_config.json: 100%|██████████| 116/116 [00:00<00:00, 5.89kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 2.30k/2.30k [00:00<00:00, 176kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.82M/1.82M [00:00<00:00, 16.6MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 117/117 [00:00<00:00, 607kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
    "cache_dir='mixtral-cache'\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir,\n",
    "                                        token=\"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\",\n",
    "                                        quantization_config=nf4_config,\n",
    "                                        device_map=\"auto\",\n",
    "                                        cache_dir=cache_dir\n",
    "                                        )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, \n",
    "                                           token=\"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\",\n",
    "                                           trust_remote_code=True, \n",
    "                                           cache_dir=cache_dir\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf5435f-5e1a-4a30-b784-fca0318c614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=False,  \n",
    "    task=\"text-generation\",\n",
    "    temperature=0.001,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    do_sample=True,\n",
    "    top_k=20,\n",
    "    max_new_tokens=400,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # if output begins repeating increase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340f4a0-8520-4a1f-80b8-a05dd3e470e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb96210-2b9a-43e4-a2ac-72a38f1818d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 1/200 [01:30<4:59:08, 90.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the 2008 - 09 season, three players on the Connecticut Huskies Women's Basketball Team managed to score over 600 points each. The top scorer was Maya Moore with an impressive total of 754 points. Following closely behind were Renee Montgomery and Tina Charles who both contributed significantly to the team's success by scoring 644 and 642 points respectively.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [01:58<2:57:08, 53.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Swiss Locomotive and Machine Works constructed a mountain railway rack steam locomotive in 1896 with SLM number 988. This particular locomotive was assigned the number 4 and shares its type, wheel arrangement (0 - 4 - 2 T), and location (Snowdon Mountain Railway) with several other locomotives built between 1895 and 1923.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [02:33<4:12:27, 76.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The data shows a general upward trend in the number of turbines installed per wind project in Maine between 2006 and 2017. In 2006, there were only 28 turbines installed for one project, but by 2016, several projects had more than 50 turbines each. For instance, two projects completed in 2016 had 56 and 17 turbines respectively. However, it's worth noting that the number of turbines varied significantly among different projects within the same year, indicating potential differences in scale or capacity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(200)):\n",
    "    prompt = generate_validate_prompt(validate_df[i])\n",
    "    res = generate_text(prompt)\n",
    "    generated_summary.append(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a2645-6882-4b5b-9524-5f334f6a84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rougeL = []\n",
    "bert = []\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "rougescore = evaluate.load(\"rouge\")\n",
    "\n",
    "bert_score = bertscore.compute(predictions=generated_summary, references=validate_df['summary'], lang = \"en\")\n",
    "rouge_score = rougescore.compute(predictions=generated_summary, references=validate_df['summary'])\n",
    "print(rouge_score, bert_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
