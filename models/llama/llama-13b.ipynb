{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b7f2ae-d22f-46cf-8b01-c2bca2b27acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install accelerate peft bitsandbytes trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dc467e-a4c0-4d77-a9d7-fc9aea21ab3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485cbb45-05c2-4389-9078-d7774b9a7d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311ea0c4-46f3-460b-8ac9-847b29b678d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 19:02:48.829566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 19:02:48.978818: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:/opt/slurm/lib64:\n",
      "2024-04-12 19:02:48.978864: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-12 19:02:49.009546: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-12 19:02:50.138173: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:/opt/slurm/lib64:\n",
      "2024-04-12 19:02:50.138339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:/opt/slurm/lib64:\n",
      "2024-04-12 19:02:50.138345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "import evaluate\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa57371-2cde-464d-91e8-cf25fc943e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_train\")\n",
    "test_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec892caa-f8a0-4226-b1b2-eee03bf7359b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 500/500 [00:00<00:00, 5536.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['row_ids', 'table', 'summary', 'query', 'example_id', 'coordinates', 'answers'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example_ids = set(test_df['example_id'])\n",
    "validate_example_ids = set(validate_df['example_id'])\n",
    "common_example_ids = test_example_ids.intersection(validate_example_ids)\n",
    "\n",
    "test_df = test_df.filter(lambda example: example['example_id'] not in common_example_ids)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7438c2e2-b5d5-4088-9052-211bb99a28d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_pandas(item):\n",
    "  return pd.DataFrame(item['table'][\"rows\"],columns=item['table'][\"header\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e861a6-5f76-4586-9722-14677957e94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_training_prompt(query: str, table: str, summary: str, system_prompt: str):\n",
    "    \n",
    "    return f\"\"\"### Instruction: {system_prompt}\n",
    "    \\n\\n### Input: \n",
    "Table: {table.strip()}\n",
    "Query: {query.strip()} \\n\\n\n",
    "### Response: {summary}\"\"\".strip()\n",
    "\n",
    "def flatten_table(table: Dict) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    title = table.get('title', [])\n",
    "\n",
    "    flattened_rows = []\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \" + row_text)\n",
    "\n",
    "    flattened_table = f\"Title: {' '.join(map(str, title))}\" + \" \" + \" \".join(flattened_rows)\n",
    "\n",
    "    return flattened_table\n",
    "\n",
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "    \n",
    "    task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "    return {\n",
    "        \"query\": data_point[\"query\"],\n",
    "        \"table\": flatten_table(data_point[\"table\"]),\n",
    "        \"summary\": data_point[\"summary\"],\n",
    "        \"text\": generate_training_prompt(data_point[\"query\"], flatten_table(data_point[\"table\"]),  data_point['summary'], task_prefix)\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(['row_ids', 'example_id', 'coordinates', 'answers']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa75f6a-0327-4a2f-9dc4-6a05bdd66c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 4061.69 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['table', 'summary', 'query', 'text'],\n",
       "     num_rows: 1200\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['table', 'summary', 'query', 'text'],\n",
       "     num_rows: 300\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['table', 'summary', 'query', 'text'],\n",
       "     num_rows: 200\n",
       " }))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
    "train_df = process_dataset(train_df)\n",
    "validate_df = process_dataset(validate_df)\n",
    "test_df = process_dataset(test_df)\n",
    "\n",
    "# Select 512 rows from the training split\n",
    "train_data = train_df.shuffle(seed=42).select([i for i in range(1200)])\n",
    "\n",
    "\n",
    "test_data = test_df.shuffle(seed=42).select([i for i in range(300)])\n",
    "validation_data = validate_df\n",
    "\n",
    "train_data,test_data,validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55684a6a-e9b9-4ead-9b97-37a305c98271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493511f6-bc4e-450f-a785-fd90d2bff396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  8.48s/it]\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"./llama-13b-cache\"\n",
    "base_model = \"meta-llama/Llama-2-13b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    #quantization_config=quant_config,\n",
    "    token=\"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\",\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True, \n",
    "                                          token=\"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\",\n",
    "                                          cache_dir=cache_dir,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7726aedf-6e4d-4b4c-b699-564cdfbccc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Given a query and a table, generate a summary that answers the query based on the information in the table: \n",
      "\n",
      "### Input:\n",
      "Table: Title: D r .   R i n t a r ō   -   E p i s o d e s ## Row 0, Directed by:Nobuo Mizuta ## Row 1, Directed by:Nobuo Mizuta ## Row 2, Directed by:Jun Aizawa ## Row 3, Directed by:Nobuo Mizuta ## Row 4, Directed by:Nobuo Mizuta ## Row 5, Directed by:Jun Aizawa ## Row 6, Directed by:Nobuo Mizuta ## Row 7, Directed by:Jun Aizawa ## Row 8, Directed by:Nobuo Mizuta ## Row 9, Directed by:Nobuo Mizuta\n",
      "Query: Over the first ten episodes, does there appear to be any correlation between the director (Nobuo Mizuta vs Jun Aizawa) and the viewership ratings?\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "In first ten episode of Dr. Rintarō, have small relation between director and how many people watch it. When Nobuo Mizuta is director, people watch more, between 10.8% and 13.9%, average 13.1% maybe. But if Jun Aizawa is director, little bit less people watch, only 11.0% to 13.7%, average maybe 12.3%. Not big change, but Mean Nobuo Mizuta episodes more liked by watchers.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "\n",
      "Given a query and a table, generate a summary that answers the query based on the information in the table: \n",
      "\n",
      "### Input:\n",
      "Table: Title: D r .   R i n t a r ō   -   E p i s o d e s ## Row 0, Directed by:Nobuo Mizuta ## Row 1, Directed by:Nobuo Mizuta ## Row 2, Directed by:Jun Aizawa ## Row 3, Directed by:Nobuo Mizuta ## Row 4, Directed by:Nobuo Mizuta ## Row 5, Directed by:Jun Aizawa ## Row 6, Directed by:Nobuo Mizuta ## Row 7, Directed by:Jun Aizawa ## Row 8, Directed by:Nobuo Mizuta ## Row 9, Directed by:Nobuo Mizuta\n",
      "Query: Over the first ten episodes, does there appear to be any correlation between the director (Nobuo Mizuta vs Jun Aizawa) and the viewership ratings?\n",
      "\n",
      "### Summary:\n",
      "- Nobuo Mizuta directed 6 of the first 10 episodes.\n",
      "- Jun Aizawa directed 4 of the first 10 episodes.\n",
      "- Nobuo Mizuta directed 5 of the first 10 episodes.\n",
      "- Jun Aizawa directed 5 of the first 10 episodes.\n",
      "\n",
      "### Output:\n",
      "- Nobuo Mizuta directed 6 of the first 10 episodes.\n",
      "- Jun Aizawa directed\n"
     ]
    }
   ],
   "source": [
    "index = 116\n",
    "\n",
    "query = test_df['query'][index]\n",
    "table = test_df['table'][index]\n",
    "summary = test_df['summary'][index]\n",
    "task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{task_prefix}\n",
    "\n",
    "### Input:\n",
    "Table: {table.strip()}\n",
    "Query: {query.strip()}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(model.generate(inputs[\"input_ids\"], max_new_tokens=100)[0], skip_special_tokens=True)\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d209432-f418-4b47-9635-2319dea05b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.05\n",
    "lora_target_modules = [\"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\",\"v_proj\", \"ln\", \"fc\"]\n",
    "\n",
    "\n",
    "peft_params = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462640e1-ddf6-41a1-9ad3-e1abc152976a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 974.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_predictions, decoded_labels = postprocess_text(decoded_predictions, decoded_labels)\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "\n",
    "    return rouge_results\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./train_weights_13b\",\n",
    "    save_strategy = \"no\",\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=6,\n",
    "     per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=-1,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.003,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.05,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    "    compute_metrics=metric_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ff4fa-d100-4604-80e2-f3e156b4d372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  18/2000 07:24 < 15:17:11, 0.04 it/s, Epoch 0.17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0f2f3-febc-4608-8e5b-46e9d3300d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = \"llama-2-13b-QTsumm\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b7bf7-6590-421c-b604-6d0e1e365a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce5784-acc1-468c-9f9d-7232f806826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "peft_model_dir = \"peft-dialogue-summary\"\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430a13d-df62-4c6d-8a5e-41245d5b319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 51\n",
    "\n",
    "query = test_df['query'][index]\n",
    "table = test_df['table'][index]\n",
    "summary = test_df['summary'][index]\n",
    "task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{task_prefix}\n",
    "\n",
    "### Input:\n",
    "Table: {table.strip()}\n",
    "Query: {query.strip()}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors='pt')\n",
    "# output = tokenizer.decode(trained_model.generate(inputs[\"input_ids\"], max_new_tokens=100)[0], skip_special_tokens=True)\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt',truncation=True).input_ids.cuda()\n",
    "outputs = trained_model.generate(input_ids=input_ids, max_new_tokens=200, )\n",
    "output= tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'TRAINED MODEL GENERATED TEXT :\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acd6ba-dbf1-4636-9cc9-975855296c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8288b9-6cbc-48ba-a40c-f78a988d1363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")\n",
    "sample = validate_df[101]\n",
    "def summarize(model, text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.0001)\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "prompt = create_prompts(sample)\n",
    "summary = summarize(model, prompt['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a80822-ed89-45b4-833f-a40e0dd24ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_validate_df = validate_df.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6352743-696a-47c4-a780-33195ead8a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid1 = validate_df.select(range(0, 10))\n",
    "valid2 = validate_df.select(range(10, 20))\n",
    "valid3 = validate_df.select(range(20, 30))\n",
    "valid4 = validate_df.select(range(30, 40))\n",
    "valid5 = validate_df.select(range(40, 50))\n",
    "valid6 = validate_df.select(range(50, 60))\n",
    "valid7 = validate_df.select(range(60, 70))\n",
    "valid8 = validate_df.select(range(70, 80))\n",
    "valid9 = validate_df.select(range(80, 90))\n",
    "valid10 = validate_df.select(range(90, 100))\n",
    "valid11 = validate_df.select(range(100, 110))\n",
    "valid12 = validate_df.select(range(110, 120))\n",
    "valid13 = validate_df.select(range(120, 130))\n",
    "valid14 = validate_df.select(range(130, 140))\n",
    "valid15= validate_df.select(range(140, 150))\n",
    "valid16 = validate_df.select(range(150, 160))\n",
    "valid17 = validate_df.select(range(160, 170))\n",
    "valid18 = validate_df.select(range(170, 180))\n",
    "valid19 = validate_df.select(range(180, 190))\n",
    "valid20 = validate_df.select(range(190, 200))\n",
    "valid = [valid1, valid2, valid3, valid4, valid5, valid6, valid7, valid8, valid9, valid10, valid11, valid12, valid13, valid14, valid15, valid16, valid17, valid18, valid19,valid20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d661d6-9bc9-4770-aaf2-50258141b88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rougeL = []\n",
    "for i in range(2):\n",
    "    va = valid[i+3].map(tokenize_function, batched=True)\n",
    "    eval_result = trainer.evaluate(va)\n",
    "    decoded_summaries = tokenizer.batch_decode(eval_results.predictions, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    # rougeL.append(metrics['test_rougeLsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516fd5e-12b0-4db7-a3da-10ab14015b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_texts = predict_results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464bd14-4060-4d1c-ab74-187059a1d0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generated_texts, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aefc49-d7b2-4e1a-be9e-37a1ebb2a83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab-llm",
   "language": "python",
   "name": "tab-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
