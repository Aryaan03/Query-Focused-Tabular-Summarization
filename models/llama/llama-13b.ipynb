{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b7f2ae-d22f-46cf-8b01-c2bca2b27acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install accelerate peft bitsandbytes trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42dc467e-a4c0-4d77-a9d7-fc9aea21ab3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485cbb45-05c2-4389-9078-d7774b9a7d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "311ea0c4-46f3-460b-8ac9-847b29b678d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-03 01:26:43.398229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "import evaluate\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa57371-2cde-464d-91e8-cf25fc943e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_train\")\n",
    "test_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec892caa-f8a0-4226-b1b2-eee03bf7359b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['row_ids', 'table', 'summary', 'query', 'example_id', 'coordinates', 'answers'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example_ids = set(test_df['example_id'])\n",
    "validate_example_ids = set(validate_df['example_id'])\n",
    "common_example_ids = test_example_ids.intersection(validate_example_ids)\n",
    "\n",
    "test_df = test_df.filter(lambda example: example['example_id'] not in common_example_ids)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7438c2e2-b5d5-4088-9052-211bb99a28d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_pandas(item):\n",
    "  return pd.DataFrame(item['table'][\"rows\"],columns=item['table'][\"header\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e861a6-5f76-4586-9722-14677957e94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_training_prompt(query: str, table: str, summary: str, system_prompt: str):\n",
    "    \n",
    "    return f\"\"\"### Instruction: {system_prompt}\n",
    "    \\n\\n### Input: \n",
    "Table: {table.strip()}\n",
    "Query: {query.strip()} \\n\\n\n",
    "### Response: {summary}\"\"\".strip()\n",
    "\n",
    "def flatten_table(table: Dict) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    title = table.get('title', [])\n",
    "\n",
    "    flattened_rows = []\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \" + row_text)\n",
    "\n",
    "    flattened_table = f\"Title: {' '.join(map(str, title))}\" + \" \" + \" \".join(flattened_rows)\n",
    "\n",
    "    return flattened_table\n",
    "\n",
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "    \n",
    "    task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "    return {\n",
    "        \"query\": data_point[\"query\"],\n",
    "        \"table\": flatten_table(data_point[\"table\"]),\n",
    "        \"summary\": data_point[\"summary\"],\n",
    "        \"text\": generate_training_prompt(data_point[\"query\"], flatten_table(data_point[\"table\"]),  data_point['summary'], task_prefix)\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(['row_ids', 'example_id', 'coordinates', 'answers']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa75f6a-0327-4a2f-9dc4-6a05bdd66c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['table', 'summary', 'query', 'text'],\n",
       "     num_rows: 512\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['table', 'summary', 'query', 'text'],\n",
       "     num_rows: 100\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['table', 'summary', 'query', 'text'],\n",
       "     num_rows: 200\n",
       " }))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
    "train_df = process_dataset(train_df)\n",
    "validate_df = process_dataset(validate_df)\n",
    "test_df = process_dataset(test_df)\n",
    "\n",
    "# Select 1000 rows from the training split\n",
    "train_data = train_df.shuffle(seed=42).select([i for i in range(512)])\n",
    "\n",
    "\n",
    "test_data = test_df.shuffle(seed=42).select([i for i in range(100)])\n",
    "validation_data = validate_df\n",
    "\n",
    "train_data,test_data,validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55684a6a-e9b9-4ead-9b97-37a305c98271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493511f6-bc4e-450f-a785-fd90d2bff396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:04<00:00, 21.56s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = \"meta-llama/Llama-2-13b-hf\"\n",
    "#base_model = \"llama-2-7b-QTsumm\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    #quantization_config=quant_config,\n",
    "    token=\"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\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True, \n",
    "                                          token=\"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\",\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7726aedf-6e4d-4b4c-b699-564cdfbccc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Given a query and a table, generate a summary that answers the query based on the information in the table: \n",
      "\n",
      "### Input:\n",
      "Table: Title: 1 9 5 3   C l e v e l a n d   B r o w n s   s e a s o n   -   R e g u l a r   S e a s o n   S c h e d u l e ## Row 0, Week:1,Date:September 27, 1953,Opponent:at Green Bay Packers,Result:W 27–0,Attendance:22,604 ## Row 1, Week:2,Date:October 4, 1953,Opponent:at Chicago Cardinals,Result:W 27–7,Attendance:24,374 ## Row 2, Week:3,Date:October 10, 1953,Opponent:Philadelphia Eagles,Result:W 37–13,Attendance:45,802 ## Row 3, Week:4,Date:October 18, 1953,Opponent:at Washington Redskins,Result:W 30–14,Attendance:33,963 ## Row 4, Week:5,Date:October 25, 1953,Opponent:at New York Giants,Result:W 7–0,Attendance:30,773 ## Row 5, Week:6,Date:November 1, 1953,Opponent:Washington Redskins,Result:W 27–3,Attendance:47,845 ## Row 6, Week:7,Date:November 8, 1953,Opponent:Pittsburgh Steelers,Result:W 34–16,Attendance:35,592 ## Row 7, Week:8,Date:November 15, 1953,Opponent:San Francisco 49ers,Result:W 23–21,Attendance:80,698 ## Row 8, Week:9,Date:November 22, 1953,Opponent:at Pittsburgh Steelers,Result:W 20–16,Attendance:32,904 ## Row 9, Week:10,Date:November 29, 1953,Opponent:Chicago Cardinals,Result:W 27–16,Attendance:24,499 ## Row 10, Week:11,Date:December 6, 1953,Opponent:New York Giants,Result:W 62–14,Attendance:40,235 ## Row 11, Week:12,Date:December 13, 1953,Opponent:at Philadelphia Eagles,Result:L 42–27,Attendance:38,654\n",
      "Query: What was the game with the highest attendance during the 1953 Cleveland Browns season, and what was the result of that game?\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "The game has highest people come watch in 1953 Cleveland Browns season was on November 15, 1953, they play with San Francisco 49ers. This game has 80,698 people come see. The game result was Cleveland Browns win only a little, final score 23-21.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "\n",
      "Given a query and a table, generate a summary that answers the query based on the information in the table: \n",
      "\n",
      "### Input:\n",
      "Table: Title: 1 9 5 3   C l e v e l a n d   B r o w n s   s e a s o n   -   R e g u l a r   S e a s o n   S c h e d u l e ## Row 0, Week:1,Date:September 27, 1953,Opponent:at Green Bay Packers,Result:W 27–0,Attendance:22,604 ## Row 1, Week:2,Date:October 4, 1953,Opponent:at Chicago Cardinals,Result:W 27–7,Attendance:24,374 ## Row 2, Week:3,Date:October 10, 1953,Opponent:Philadelphia Eagles,Result:W 37–13,Attendance:45,802 ## Row 3, Week:4,Date:October 18, 1953,Opponent:at Washington Redskins,Result:W 30–14,Attendance:33,963 ## Row 4, Week:5,Date:October 25, 1953,Opponent:at New York Giants,Result:W 7–0,Attendance:30,773 ## Row 5, Week:6,Date:November 1, 1953,Opponent:Washington Redskins,Result:W 27–3,Attendance:47,845 ## Row 6, Week:7,Date:November 8, 1953,Opponent:Pittsburgh Steelers,Result:W 34–16,Attendance:35,592 ## Row 7, Week:8,Date:November 15, 1953,Opponent:San Francisco 49ers,Result:W 23–21,Attendance:80,698 ## Row 8, Week:9,Date:November 22, 1953,Opponent:at Pittsburgh Steelers,Result:W 20–16,Attendance:32,904 ## Row 9, Week:10,Date:November 29, 1953,Opponent:Chicago Cardinals,Result:W 27–16,Attendance:24,499 ## Row 10, Week:11,Date:December 6, 1953,Opponent:New York Giants,Result:W 62–14,Attendance:40,235 ## Row 11, Week:12,Date:December 13, 1953,Opponent:at Philadelphia Eagles,Result:L 42–27,Attendance:38,654\n",
      "Query: What was the game with the highest attendance during the 1953 Cleveland Browns season, and what was the result of that game?\n",
      "\n",
      "### Summary:\n",
      "Row 0, Week:1,Date:September 27, 1953,Opponent:at Green Bay Packers,Result:W 27–0,Attendance:22,604\n",
      "Row 1, Week:2,Date:October 4, 1953,Opponent:at Chicago Cardinals,Result:W 27–7,Attendance:24,37\n"
     ]
    }
   ],
   "source": [
    "index = 79\n",
    "\n",
    "query = test_df['query'][index]\n",
    "table = test_df['table'][index]\n",
    "summary = test_df['summary'][index]\n",
    "task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{task_prefix}\n",
    "\n",
    "### Input:\n",
    "Table: {table.strip()}\n",
    "Query: {query.strip()}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(model.generate(inputs[\"input_ids\"], max_new_tokens=100)[0], skip_special_tokens=True)\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d209432-f418-4b47-9635-2319dea05b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\",\"v_proj\", \"ln\", \"fc\"]\n",
    "\n",
    "\n",
    "peft_params = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462640e1-ddf6-41a1-9ad3-e1abc152976a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 512/512 [00:09<00:00, 56.25 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 858.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # rougeLSum expects newline after each sentence\n",
    "        preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_predictions, decoded_labels = postprocess_text(decoded_predictions, decoded_labels)\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "\n",
    "    return rouge_results\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./train_weights_13b\",\n",
    "    save_strategy = \"no\",\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=6,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=-1,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.003,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.05,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    "    compute_metrics=metric_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ff4fa-d100-4604-80e2-f3e156b4d372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 40/860 15:51 < 5:42:07, 0.04 it/s, Epoch 0.91/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.685200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc0f2f3-febc-4608-8e5b-46e9d3300d46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama-2-7b-QTsumm/tokenizer_config.json',\n",
       " 'llama-2-7b-QTsumm/special_tokens_map.json',\n",
       " 'llama-2-7b-QTsumm/tokenizer.model',\n",
       " 'llama-2-7b-QTsumm/added_tokens.json',\n",
       " 'llama-2-7b-QTsumm/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = \"llama-2-13b-QTsumm\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b7bf7-6590-421c-b604-6d0e1e365a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce5784-acc1-468c-9f9d-7232f806826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "peft_model_dir = \"peft-dialogue-summary\"\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430a13d-df62-4c6d-8a5e-41245d5b319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 51\n",
    "\n",
    "query = test_df['query'][index]\n",
    "table = test_df['table'][index]\n",
    "summary = test_df['summary'][index]\n",
    "task_prefix = \"Given a query and a table, generate a summary that answers the query based on the information in the table: \"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{task_prefix}\n",
    "\n",
    "### Input:\n",
    "Table: {table.strip()}\n",
    "Query: {query.strip()}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors='pt')\n",
    "# output = tokenizer.decode(trained_model.generate(inputs[\"input_ids\"], max_new_tokens=100)[0], skip_special_tokens=True)\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt',truncation=True).input_ids.cuda()\n",
    "outputs = trained_model.generate(input_ids=input_ids, max_new_tokens=200, )\n",
    "output= tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'TRAINED MODEL GENERATED TEXT :\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acd6ba-dbf1-4636-9cc9-975855296c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e8288b9-6cbc-48ba-a40c-f78a988d1363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")\n",
    "sample = validate_df[101]\n",
    "def summarize(model, text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.0001)\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "prompt = create_prompts(sample)\n",
    "summary = summarize(model, prompt['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a80822-ed89-45b4-833f-a40e0dd24ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_validate_df = validate_df.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6352743-696a-47c4-a780-33195ead8a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid1 = validate_df.select(range(0, 10))\n",
    "valid2 = validate_df.select(range(10, 20))\n",
    "valid3 = validate_df.select(range(20, 30))\n",
    "valid4 = validate_df.select(range(30, 40))\n",
    "valid5 = validate_df.select(range(40, 50))\n",
    "valid6 = validate_df.select(range(50, 60))\n",
    "valid7 = validate_df.select(range(60, 70))\n",
    "valid8 = validate_df.select(range(70, 80))\n",
    "valid9 = validate_df.select(range(80, 90))\n",
    "valid10 = validate_df.select(range(90, 100))\n",
    "valid11 = validate_df.select(range(100, 110))\n",
    "valid12 = validate_df.select(range(110, 120))\n",
    "valid13 = validate_df.select(range(120, 130))\n",
    "valid14 = validate_df.select(range(130, 140))\n",
    "valid15= validate_df.select(range(140, 150))\n",
    "valid16 = validate_df.select(range(150, 160))\n",
    "valid17 = validate_df.select(range(160, 170))\n",
    "valid18 = validate_df.select(range(170, 180))\n",
    "valid19 = validate_df.select(range(180, 190))\n",
    "valid20 = validate_df.select(range(190, 200))\n",
    "valid = [valid1, valid2, valid3, valid4, valid5, valid6, valid7, valid8, valid9, valid10, valid11, valid12, valid13, valid14, valid15, valid16, valid17, valid18, valid19,valid20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d661d6-9bc9-4770-aaf2-50258141b88d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m     va \u001b[38;5;241m=\u001b[39m valid[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mva\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     decoded_summaries \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(eval_results\u001b[38;5;241m.\u001b[39mpredictions, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# rougeL.append(metrics['test_rougeLsum'])\u001b[39;00m\n",
      "File \u001b[0;32m/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/transformers/trainer.py:3019\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3016\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3018\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3019\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/transformers/trainer.py:3310\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3306\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3307\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3308\u001b[0m         )\n\u001b[1;32m   3309\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3310\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3312\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mmetric_fn\u001b[0;34m(eval_predictions)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetric_fn\u001b[39m(eval_predictions):\n\u001b[1;32m     12\u001b[0m     predictions, labels \u001b[38;5;241m=\u001b[39m eval_predictions\n\u001b[0;32m---> 13\u001b[0m     decoded_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m     15\u001b[0m         label[label \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id  \u001b[38;5;66;03m# Replace masked label tokens\u001b[39;00m\n",
      "File \u001b[0;32m/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3710\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3688\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3691\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3692\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3693\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3694\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3695\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3708\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   3711\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m   3712\u001b[0m             seq,\n\u001b[1;32m   3713\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3714\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3715\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3716\u001b[0m         )\n\u001b[1;32m   3717\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3718\u001b[0m     ]\n",
      "File \u001b[0;32m/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3711\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3688\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3691\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3692\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3693\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3694\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3695\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3708\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 3711\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3718\u001b[0m     ]\n",
      "File \u001b[0;32m/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3750\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3748\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/cai6307/y.khan/conda/envs/tabllm/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:625\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    624\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 625\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    628\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    631\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "rougeL = []\n",
    "for i in range(2):\n",
    "    va = valid[i+3].map(tokenize_function, batched=True)\n",
    "    eval_result = trainer.evaluate(va)\n",
    "    decoded_summaries = tokenizer.batch_decode(eval_results.predictions, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    # rougeL.append(metrics['test_rougeLsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b516fd5e-12b0-4db7-a3da-10ab14015b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_texts = predict_results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464bd14-4060-4d1c-ab74-187059a1d0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generated_texts, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aefc49-d7b2-4e1a-be9e-37a1ebb2a83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab-llm",
   "language": "python",
   "name": "tab-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
