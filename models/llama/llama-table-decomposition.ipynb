{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbdc06f-3620-400c-ad35-69025f0246ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import torch \n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f4ae86-ba1d-4436-9909-7b96c1eca0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    ")\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "from typing import List, Dict\n",
    "\n",
    "train_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/data/train\")\n",
    "test_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/data/test\")\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/data/validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1dabe59-a37e-478e-82b6-4ae6aeca32de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [04:17<00:00,  8.59s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "cache_dir='./llama3-70B_cache'\n",
    "model_dir = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    quantization_config=nf4_config,\n",
    "    token=\"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\",\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True, \n",
    "                                          token=\"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\",\n",
    "                                          cache_dir=cache_dir\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ded7f39-5d73-47fc-8dc0-b276c6e1dbf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_table(table: Dict) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    \n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \" + row_text)\n",
    "\n",
    "    flattened_table = \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "task = f\"\"\"Given a table and a user query, your task is to extract only the columns that are essential for summarizing the information relevant to the query. The summarization should capture the key insights and statistics related to the user's information need.\n",
    "To achieve this, you will need to:\n",
    "1. Understand the user's query and identify the main entities, attributes, and analysis that the user is interested in.\n",
    "2. Analyze the column names, data types, and sample values to determine which columns contain the core entities and numeric/categorical data relevant for summarization.\n",
    "3. Exclude any columns that seem peripheral or redundant for the purposes of summarizing the key information requested.\n",
    "4. Output a comma-separated list of only the column names that are essential for summarizing the query.\n",
    "5. If no columns seem directly relevant for summarizing the user's query, output a message stating that the table does not contain suitable information.\n",
    "\n",
    "Your response should be a single line listing the relevant column names, or a statement that no columns apply, for example:\n",
    "\"product_name, sales_amount, region, quarter\"\n",
    "or \n",
    "\"This table does not have columns relevant for summarizing [query]\"\n",
    "I'll provide the table and query next, and you can demonstrate extracting the essential columns for summarization.\"\"\"\n",
    "\n",
    "def generate_validate_prompt(examples):\n",
    "    table = examples['table']\n",
    "    query = examples['query']\n",
    "    summary = examples['summary']\n",
    "    table_title = table['title']\n",
    "    system_prompt = \"You are a helpful, respectful and honest assistant. Below is an instruction that describes a query-focused summarization task. Write a summary that appropriately response to the user query.\"\n",
    "    \n",
    "    task = \"Using the information from the above table, give the name of relevant columns in the given table that support or oppose the following user query.\"\n",
    "\n",
    "    \n",
    "    flattened_table = flatten_table(table)\n",
    "    input_text = f\"Table Title: {table_title}\\n{flattened_table}\\n{task}\\nQuery: {query}\\n\\nColumn names:\\n\"\n",
    "    prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "{input_text} [/INST]\"\"\"\n",
    "    prompt = input_text\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10e61c39-a514-45f9-b51d-4c98a20666f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Title: Swiss Locomotive And Machine Works\n",
      "## Row 0, Built:1895,Number:1,Type:Mountain Railway Rack Steam Locomotive,Slm Number:923,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Ladas ## Row 1, Built:1895,Number:2,Type:Mountain Railway Rack Steam Locomotive,Slm Number:924,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Enid ## Row 2, Built:1895,Number:3,Type:Mountain Railway Rack Steam Locomotive,Slm Number:925,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Wyddfa ## Row 3, Built:1896,Number:4,Type:Mountain Railway Rack Steam Locomotive,Slm Number:988,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Snowdon ## Row 4, Built:1896,Number:5,Type:Mountain Railway Rack Steam Locomotive,Slm Number:989,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Moel Siabod ## Row 5, Built:1922,Number:6,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2838,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Padarn ## Row 6, Built:1923,Number:7,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2869,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Ralph ## Row 7, Built:1923,Number:8,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2870,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Eryri\n",
      "Using the information from the above table, give the name of relevant columns in the given table that support or oppose the following user query.\n",
      "Query: Summarize the basic information of the locomotive(s) built by Swiss Locomotive and Machine Works with slm number 988.\n",
      "\n",
      "Column names:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_validate_prompt(validate_df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f8e7ae-e941-40e6-9126-7b27f33d6606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [05:05<00:00, 10.17s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "cache_dir='./llama3-70B_cache'\n",
    "model_dir = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    quantization_config=nf4_config,\n",
    "    token=\"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\",\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True, \n",
    "                                          token=\"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\",\n",
    "                                          cache_dir=cache_dir\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b06440-f991-468b-82d3-357aa9014755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Title: Swiss Locomotive And Machine Works\n",
      "## Row 0, Built:1895,Number:1,Type:Mountain Railway Rack Steam Locomotive,Slm Number:923,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Ladas ## Row 1, Built:1895,Number:2,Type:Mountain Railway Rack Steam Locomotive,Slm Number:924,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Enid ## Row 2, Built:1895,Number:3,Type:Mountain Railway Rack Steam Locomotive,Slm Number:925,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Wyddfa ## Row 3, Built:1896,Number:4,Type:Mountain Railway Rack Steam Locomotive,Slm Number:988,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Snowdon ## Row 4, Built:1896,Number:5,Type:Mountain Railway Rack Steam Locomotive,Slm Number:989,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Moel Siabod ## Row 5, Built:1922,Number:6,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2838,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Padarn ## Row 6, Built:1923,Number:7,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2869,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Ralph ## Row 7, Built:1923,Number:8,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2870,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway,Notes:Eryri\n",
      "Using the information from the table, generate a paragraph-long summary to response to the following user query:\n",
      "Query: Summarize the basic information of the locomotive(s) built by Swiss Locomotive and Machine Works with slm number 988.\n",
      "\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_validate_prompt(validate_df[1])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e850dd39-86cf-41a6-aff1-96c0957f17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26ddde34-71b4-4aab-998c-0f6a81e0e7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 1/200 [00:26<1:27:55, 26.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 2/200 [00:39<1:00:16, 18.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 3/200 [00:54<55:58, 17.05s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 4/200 [01:13<58:27, 17.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 4/200 [01:23<1:08:20, 20.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "output_summary = []\n",
    "for i in tqdm(range(200)):\n",
    "    prompt = generate_validate_prompt(validate_df[i])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful, respectful and honest assistant. Below is an instruction that describes a query-based table decomposition task\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=400,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.0001,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    output_summary.append(outputs[0][\"generated_text\"][len(prompt):])\n",
    "    if (i == 4) :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29552cf-cffb-4097-9e42-a48623f15902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided table, the relevant columns that support the user query are:\n",
      "\n",
      "* `Player`\n",
      "* `Points`\n",
      "\n",
      "These columns are necessary to identify the players who scored more than 600 points in the 2008-09 Connecticut Huskies Women's Basketball Team.\n",
      "\n",
      "After analyzing the table, I found that there are two players who scored more than 600 points:\n",
      "\n",
      "1. **Moore Maya Moore**: She scored 754 points.\n",
      "2. **Montgomery Renee Montgomery**: She scored 644 points. (Although she didn't exactly score more than 600 points, she came close with 644 points.)\n",
      "\n",
      "Note that there are no players who scored exactly more than 600 points, but these two players are the closest to achieving that milestone.\n",
      "Based on the provided table, the relevant column names that support the user query are:\n",
      "\n",
      "* Built\n",
      "* Slm Number\n",
      "* Number\n",
      "* Type\n",
      "* Wheel Arrangement\n",
      "* Location\n",
      "* Notes\n",
      "\n",
      "These columns provide the basic information about the locomotive(s) built by Swiss Locomotive and Machine Works with slm number 988.\n",
      "To support the user query, the relevant column names from the given table are:\n",
      "\n",
      "1. **Completed** (to analyze the trend over the years)\n",
      "2. **Number of Turbines** (to examine the number of turbines installed per project)\n",
      "\n",
      "These two columns will allow us to analyze the trend in the number of turbines installed per project over the years from 2006 to 2017.\n",
      "Based on the provided table, the relevant column names that support or oppose the user query are:\n",
      "\n",
      "* Object Type: This column is relevant because it helps identify the objects of type \"Open Cluster\".\n",
      "* Constellation: This column is relevant because it helps identify the objects located in the \"Columba\" constellation.\n",
      "\n",
      "Note that there are no objects of type \"Open Cluster\" located in the Columba constellation in the provided table. The object located in Columba is of type \"Spiral Galaxy\" (Row 11).\n",
      "To answer the user query, we need to focus on the columns that provide information about the BPM and the country where the artists are based. \n",
      "\n",
      "The relevant column names are:\n",
      "\n",
      "1. BPM\n",
      "2. From or based in\n"
     ]
    }
   ],
   "source": [
    "for column in output_summary:\n",
    "    print (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91410212-4d54-4f61-ba91-8bdca0a81f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
