{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71f496c-efd6-4efb-be8b-35bbe72efbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import torch \n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf37c957-876b-4615-9754-4ed5d6ab6081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from typing import List, Dict\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    ")\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "from typing import List, Dict\n",
    "\n",
    "train_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_train\")\n",
    "test_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_test\")\n",
    "validate_df = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/decomposed/decomposed_validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363cd211-94de-4516-bae2-a4ef0de15e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_table(table: Dict) -> str:\n",
    "    header = table.get('header', [])\n",
    "    rows = table.get('rows', [])\n",
    "    \n",
    "    flattened_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = f\"Row {i}, \" + \",\".join([f\"{col}:{val}\" for col, val in zip(header, row)])\n",
    "        flattened_rows.append(\"## \" + row_text)\n",
    "\n",
    "    flattened_table = \" \".join(flattened_rows)\n",
    "    return flattened_table\n",
    "\n",
    "def generate_validate_prompt(examples):\n",
    "    table = examples['table']\n",
    "    query = examples['query']\n",
    "    summary = examples['summary']\n",
    "    table_title = table['title']\n",
    "    system_prompt = \"You are a helpful, respectful and honest assistant. Below is an instruction that describes a query-focused summarization task. Write a summary that appropriately response to the user query.\"\n",
    "    \n",
    "    task = \"Using the information from the table, generate a paragraph-long summary to response to the following user query:\"\n",
    "\n",
    "    \n",
    "    flattened_table = flatten_table(table)\n",
    "    input_text = f\"Table Title: {table_title}\\n{flattened_table}\\n{task}\\nQuery: {query}\\n\\nSummary:\\n\"\n",
    "    prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "{input_text} [/INST]\"\"\"\n",
    "    #prompt = f\"{system_prompt}\\n{input_text}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4dbbf6-6f0f-4d89-9164-206b5a2363ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Below is an instruction that describes a query-focused summarization task. Write a summary that appropriately response to the user query.\n",
      "<</SYS>>\n",
      "Table Title: Swiss Locomotive And Machine Works\n",
      "## Row 0, Built:1895,Number:1,Type:Mountain Railway Rack Steam Locomotive,Slm Number:923,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 1, Built:1895,Number:2,Type:Mountain Railway Rack Steam Locomotive,Slm Number:924,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 2, Built:1895,Number:3,Type:Mountain Railway Rack Steam Locomotive,Slm Number:925,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 3, Built:1896,Number:4,Type:Mountain Railway Rack Steam Locomotive,Slm Number:988,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 4, Built:1896,Number:5,Type:Mountain Railway Rack Steam Locomotive,Slm Number:989,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 5, Built:1922,Number:6,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2838,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 6, Built:1923,Number:7,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2869,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway ## Row 7, Built:1923,Number:8,Type:Mountain Railway Rack Steam Locomotive,Slm Number:2870,Wheel Arrangement:0 - 4 - 2 T,Location:Snowdon Mountain Railway\n",
      "Using the information from the table, generate a paragraph-long summary to response to the following user query:\n",
      "Query: Summarize the basic information of the locomotive(s) built by Swiss Locomotive and Machine Works with slm number 988.\n",
      "\n",
      "Summary:\n",
      " [/INST]\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_validate_prompt(validate_df[1])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6de6929-16b0-420d-b96f-126ee6b1ec1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [05:26<00:00, 10.89s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"abacusai/Smaug-72B-v0.1\"\n",
    "cache_dir='smaug-cache'\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir,\n",
    "                                        token=\"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\",\n",
    "                                        quantization_config=nf4_config,\n",
    "                                        device_map=\"auto\",\n",
    "                                        cache_dir=cache_dir\n",
    "                                        )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, \n",
    "                                           token=\"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\",\n",
    "                                           trust_remote_code=True, \n",
    "                                           cache_dir=cache_dir\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60d5403-7591-4ab3-89a5-012eef459b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=False,  \n",
    "    task=\"text-generation\",\n",
    "    temperature=0.001,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    do_sample=True,\n",
    "    top_k=20,\n",
    "    max_new_tokens=400,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # if output begins repeating increase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ffd6260-4d0d-4be2-9ae7-1284ef0feb04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a7cea2-54e3-4f0f-9a1f-6b2c54b3ac19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:01:39<00:00, 18.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(200)):\n",
    "    prompt = generate_validate_prompt(validate_df[i])\n",
    "    res = generate_text(prompt)\n",
    "    generated_summary.append(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be0be8a0-e5e7-4bc5-9d9b-2a3063ca81a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecaa9c7b-3e6f-48d6-a90f-06c29945088d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:06:44<00:00, 20.02s/it]\n"
     ]
    }
   ],
   "source": [
    "validate = load_from_disk(\"/home/y.khan/cai6307-y.khan/Query-Focused-Tabular-Summarization/data/data/validate\")\n",
    "for i in tqdm(range(200)):\n",
    "    prompt = generate_validate_prompt(validate[i])\n",
    "    res = generate_text(prompt)\n",
    "    predicted_summary.append(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c2f6f1-7119-4d51-805e-19fbd6d1c303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.4639356730374806, 'rouge2': 0.21625065684295014, 'rougeL': 0.33671618906916884, 'rougeLsum': 0.3369727012249729} {'precision': [0.9195883274078369, 0.9216462969779968, 0.8823371529579163, 0.8430105447769165, 0.907228946685791, 0.9630222916603088, 0.8906835317611694, 0.8986313343048096, 0.8711152076721191, 0.9169199466705322, 0.8346363306045532, 0.9277668595314026, 0.8855714201927185, 0.8789509534835815, 0.8557708263397217, 0.9388769865036011, 0.9087942838668823, 0.8560540080070496, 0.8907759189605713, 0.9131604433059692, 0.928785502910614, 0.9318164587020874, 0.8918784260749817, 0.9505659341812134, 0.8600481748580933, 0.935197651386261, 0.9470973014831543, 0.8832494616508484, 0.8809840679168701, 0.9033607244491577, 0.8334094285964966, 0.862772524356842, 0.8951584100723267, 0.8088887929916382, 0.895728349685669, 0.8742184638977051, 0.9235439300537109, 0.9346218109130859, 0.8845429420471191, 0.8767161965370178, 0.9346142411231995, 0.9067267179489136, 0.8625731468200684, 0.929107666015625, 0.9551087021827698, 0.9100028276443481, 0.938164472579956, 0.8749194741249084, 0.8681507706642151, 0.9090936183929443, 0.8689815998077393, 0.9421225786209106, 0.9059099555015564, 0.8742129802703857, 0.8815344572067261, 0.8827791213989258, 0.8970088958740234, 0.8741717338562012, 0.8548250198364258, 0.8617998361587524, 0.8947862386703491, 0.9075387716293335, 0.8310500383377075, 0.9068197011947632, 0.9240293502807617, 0.8885740637779236, 0.8886348009109497, 0.9127936363220215, 0.8564385175704956, 0.8646247386932373, 0.8879505395889282, 0.9209187030792236, 0.8843488693237305, 0.9590585231781006, 0.9069982767105103, 0.8639491200447083, 0.9401751756668091, 0.8968530893325806, 0.8695828914642334, 0.8511292338371277, 0.9302701354026794, 0.9312491416931152, 0.8227626085281372, 0.8531177043914795, 0.9194364547729492, 0.8782997131347656, 0.963817834854126, 0.8521273732185364, 0.8595572710037231, 0.9335653781890869, 0.9510861039161682, 0.9509950280189514, 0.89436936378479, 0.9067794680595398, 0.8888956904411316, 0.8810678720474243, 0.8810996413230896, 0.8822194337844849, 0.9484557509422302, 0.8852569460868835, 0.8723249435424805, 0.8726011514663696, 0.843270480632782, 0.866396427154541, 0.8561022281646729, 0.8631413578987122, 0.9351310729980469, 0.9338680505752563, 0.9495322108268738, 0.8943761587142944, 0.9611579775810242, 0.8850467801094055, 0.9226893186569214, 0.9012454748153687, 0.9151308536529541, 0.8110852241516113, 0.915558397769928, 0.908418595790863, 0.9025853872299194, 0.8756246566772461, 0.8819380402565002, 0.9330565929412842, 0.8323535919189453, 0.852381706237793, 0.8661904335021973, 0.920874834060669, 0.9224807024002075, 0.9118285179138184, 0.9429996013641357, 0.8582050800323486, 0.9326815009117126, 0.8981481790542603, 0.8878768682479858, 0.8800240755081177, 0.921022891998291, 0.9001073837280273, 0.8850797414779663, 0.9001492857933044, 0.8550633788108826, 0.8176441192626953, 0.8582558631896973, 0.8827784061431885, 0.8993931412696838, 0.8427309393882751, 0.9033850431442261, 0.880540668964386, 0.8977093696594238, 0.9090752005577087, 0.8962570428848267, 0.8973392248153687, 0.8989101052284241, 0.9146922826766968, 0.9466403722763062, 0.8659297823905945, 0.866503119468689, 0.8713365793228149, 0.9148808717727661, 0.8736135363578796, 0.8169275522232056, 0.9596045017242432, 0.865770697593689, 0.8669405579566956, 0.9068500995635986, 0.937286376953125, 0.9435687065124512, 0.8909059166908264, 0.9405501484870911, 0.9208402633666992, 0.9034081697463989, 0.9397918581962585, 0.9006104469299316, 0.8319362998008728, 0.9181100130081177, 0.8787182569503784, 0.9678041338920593, 0.8503096103668213, 0.9020105600357056, 0.8659107685089111, 0.9042620062828064, 0.9205412268638611, 0.9199001789093018, 0.9271005988121033, 0.9305884838104248, 0.8885224461555481, 0.8955572843551636, 0.8976739645004272, 0.8554461002349854, 0.8792461156845093, 0.9159201979637146, 0.9375578165054321, 0.9232033491134644, 0.8686800599098206, 0.8892208933830261, 0.8844544291496277, 0.948182225227356, 0.8838978409767151, 0.8694039583206177, 0.9300352334976196, 0.8957927227020264, 0.8158129453659058], 'recall': [0.8730204701423645, 0.9208316802978516, 0.8690561056137085, 0.8169320821762085, 0.9183300137519836, 0.9690548777580261, 0.8453437685966492, 0.9298036098480225, 0.8850347995758057, 0.9236149787902832, 0.8715078234672546, 0.9394405484199524, 0.8663268685340881, 0.8572754859924316, 0.9141219854354858, 0.9520554542541504, 0.8937623500823975, 0.8178053498268127, 0.8772144317626953, 0.9380659461021423, 0.9415965676307678, 0.9202179908752441, 0.871884822845459, 0.9453321695327759, 0.8454713821411133, 0.8960793018341064, 0.9516392350196838, 0.9115191698074341, 0.8774824142456055, 0.9065095782279968, 0.9152134656906128, 0.8682358264923096, 0.9217538237571716, 0.881975531578064, 0.9296338558197021, 0.8928471207618713, 0.9154652953147888, 0.9043302536010742, 0.8749344348907471, 0.8789210915565491, 0.9148654341697693, 0.9500651359558105, 0.8681436777114868, 0.9531956911087036, 0.9646998643875122, 0.8619434237480164, 0.9433383941650391, 0.8882440328598022, 0.8696218729019165, 0.9394411444664001, 0.8972141742706299, 0.9202895760536194, 0.8897358179092407, 0.8927401304244995, 0.9164751172065735, 0.9054962396621704, 0.8811475038528442, 0.8904286623001099, 0.8432995676994324, 0.8896119594573975, 0.8823572397232056, 0.9193547964096069, 0.813284158706665, 0.8998842239379883, 0.9645448327064514, 0.9234934449195862, 0.8807233572006226, 0.8725429773330688, 0.8927505016326904, 0.8742945790290833, 0.8477813005447388, 0.8818950057029724, 0.8839024305343628, 0.9336496591567993, 0.9372873306274414, 0.8794611096382141, 0.9255531430244446, 0.8726966381072998, 0.8919863700866699, 0.9144843816757202, 0.9493978023529053, 0.921392560005188, 0.8729261755943298, 0.916782557964325, 0.9211392998695374, 0.9286215901374817, 0.9404014945030212, 0.8900461196899414, 0.8791912794113159, 0.9316768646240234, 0.9343982338905334, 0.9226263761520386, 0.8723264932632446, 0.9015132784843445, 0.8853424787521362, 0.8418720960617065, 0.8736422657966614, 0.9103558659553528, 0.8851704597473145, 0.872138261795044, 0.9126290678977966, 0.8606925010681152, 0.9089100956916809, 0.872522234916687, 0.8675026893615723, 0.8670732975006104, 0.9208695888519287, 0.9198201298713684, 0.9251317977905273, 0.899355411529541, 0.9030877351760864, 0.8625622987747192, 0.9460686445236206, 0.8614172339439392, 0.9040831923484802, 0.8954024314880371, 0.8877643346786499, 0.9168784022331238, 0.9142938852310181, 0.9033358097076416, 0.8729569911956787, 0.9510111808776855, 0.9060200452804565, 0.8883950710296631, 0.9017947912216187, 0.8969374299049377, 0.909582257270813, 0.9195272922515869, 0.8675132393836975, 0.894751787185669, 0.9301038980484009, 0.9130100011825562, 0.8917980194091797, 0.9204970598220825, 0.8317923545837402, 0.9149260520935059, 0.8537948131561279, 0.8842034339904785, 0.8955411314964294, 0.8840618133544922, 0.851621150970459, 0.8917576670646667, 0.8842468857765198, 0.866650402545929, 0.9016879796981812, 0.8707897663116455, 0.8929200768470764, 0.905102014541626, 0.88233482837677, 0.9121346473693848, 0.8935356140136719, 0.8892270922660828, 0.901168942451477, 0.8784209489822388, 0.8510963916778564, 0.8810899257659912, 0.9216766357421875, 0.9433084726333618, 0.8574669361114502, 0.9627377986907959, 0.8811880350112915, 0.9071133732795715, 0.9255714416503906, 0.9348111748695374, 0.9415167570114136, 0.9100775718688965, 0.9506474137306213, 0.9110056757926941, 0.8901305794715881, 0.925119936466217, 0.9516792893409729, 0.9242823719978333, 0.8850722312927246, 0.8601037263870239, 0.913571834564209, 0.8661314249038696, 0.8709333539009094, 0.8622653484344482, 0.8954490423202515, 0.9490408897399902, 0.9075675010681152, 0.8699727654457092, 0.90004962682724, 0.9031766653060913, 0.9116968512535095, 0.9066145420074463, 0.8572484254837036, 0.8708488941192627, 0.8929718732833862, 0.9517792463302612, 0.9406365156173706, 0.9096884727478027, 0.922977089881897, 0.8783328533172607, 0.9505014419555664, 0.8951522707939148, 0.9250738024711609, 0.9296120405197144, 0.8853220343589783, 0.8622322678565979], 'f1': [0.8956995606422424, 0.9212387800216675, 0.8756462335586548, 0.8297665119171143, 0.9127457141876221, 0.966029167175293, 0.8674216270446777, 0.9139517545700073, 0.8780198097229004, 0.9202552437782288, 0.8526736497879028, 0.933567225933075, 0.8758434653282166, 0.8679779171943665, 0.8839845657348633, 0.9454203248023987, 0.901215672492981, 0.836492657661438, 0.8839432001113892, 0.9254456758499146, 0.9351471662521362, 0.9259809255599976, 0.8817683458328247, 0.9479418396949768, 0.852697491645813, 0.9152206778526306, 0.9493628740310669, 0.8971617221832275, 0.8792297840118408, 0.9049324989318848, 0.8723979592323303, 0.8654955625534058, 0.9082614779472351, 0.8438526391983032, 0.9123662114143372, 0.8834346532821655, 0.9194868206977844, 0.9192265868186951, 0.8797124624252319, 0.8778172731399536, 0.9246343970298767, 0.9278901219367981, 0.8653494119644165, 0.9409975409507751, 0.9598802924156189, 0.8853214383125305, 0.9407442808151245, 0.8815313577651978, 0.8688856959342957, 0.9240182638168335, 0.8828722238540649, 0.9310780763626099, 0.8977500796318054, 0.8833794593811035, 0.8986653089523315, 0.8939933776855469, 0.8890074491500854, 0.8822252750396729, 0.849023163318634, 0.8754850625991821, 0.8885282278060913, 0.9134085774421692, 0.8220711350440979, 0.9033386707305908, 0.9438524842262268, 0.9056973457336426, 0.8846613764762878, 0.8922145962715149, 0.8742175698280334, 0.869432806968689, 0.867401123046875, 0.9009844660758972, 0.8841256499290466, 0.9461835622787476, 0.9218940734863281, 0.871636152267456, 0.9328068494796753, 0.8846099972724915, 0.8806421756744385, 0.8816701769828796, 0.9397366046905518, 0.9262946844100952, 0.8471024036407471, 0.8838050961494446, 0.9202871322631836, 0.9027599692344666, 0.9519656300544739, 0.8706741333007812, 0.8692634105682373, 0.9326201677322388, 0.9426683187484741, 0.9365959167480469, 0.8832103610038757, 0.9041386842727661, 0.8871155381202698, 0.8610242009162903, 0.87735515832901, 0.8960667848587036, 0.9157209396362305, 0.8786486387252808, 0.892021894454956, 0.8666059374809265, 0.8748608231544495, 0.8694485425949097, 0.8617647886276245, 0.8651028871536255, 0.9279455542564392, 0.9267908334732056, 0.9371731877326965, 0.8968588709831238, 0.9312184453010559, 0.8736599087715149, 0.9342327117919922, 0.8808814287185669, 0.9095734357833862, 0.8511607646942139, 0.9014471769332886, 0.9126288890838623, 0.9084019064903259, 0.8892643451690674, 0.8774245977401733, 0.9419483542442322, 0.8676259517669678, 0.8700158596038818, 0.883634090423584, 0.9087485671043396, 0.9159861207008362, 0.9156616926193237, 0.9036828279495239, 0.8760974407196045, 0.9313909411430359, 0.905518114566803, 0.8898330926895142, 0.8998056650161743, 0.8741363883018494, 0.9074562191963196, 0.8691558837890625, 0.8921050429344177, 0.8748342990875244, 0.8495568037033081, 0.8549256920814514, 0.8872452974319458, 0.8917557001113892, 0.8545233011245728, 0.9025357365608215, 0.8756381273269653, 0.8953083157539368, 0.9070842266082764, 0.8892413973808289, 0.9046764373779297, 0.8962147831916809, 0.9017799496650696, 0.923345148563385, 0.8721306920051575, 0.8587306141853333, 0.8761861324310303, 0.9182661771774292, 0.9071242809295654, 0.8367065191268921, 0.9611685872077942, 0.8734113574028015, 0.8865721225738525, 0.9161151647567749, 0.9360471367835999, 0.9425416588783264, 0.9003897309303284, 0.945571780204773, 0.9158965945243835, 0.8967201709747314, 0.9323981404304504, 0.9254409074783325, 0.875681459903717, 0.9012885093688965, 0.8693113923072815, 0.9399062991142273, 0.8581476211547852, 0.8861995339393616, 0.8640842437744141, 0.8998340368270874, 0.934573769569397, 0.9136922359466553, 0.897628664970398, 0.91506427526474, 0.895789623260498, 0.9035550355911255, 0.9021220803260803, 0.8563463091850281, 0.8750273585319519, 0.9043005108833313, 0.9446150064468384, 0.9318383932113647, 0.8887115120887756, 0.9057846069335938, 0.8813830018043518, 0.9493404030799866, 0.889489471912384, 0.8963753581047058, 0.9298235774040222, 0.890526533126831, 0.8383805155754089], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.36.2)'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rougeL = []\n",
    "bert = []\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "rougescore = evaluate.load(\"rouge\")\n",
    "\n",
    "bert_score = bertscore.compute(predictions=generated_summary, references=validate_df['summary'], lang = \"en\")\n",
    "rouge_score = rougescore.compute(predictions=generated_summary, references=validate_df['summary'])\n",
    "print(rouge_score, bert_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73225cf7-5780-4088-9327-021c22266b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.49010609919109493, 'rouge2': 0.2333976706539606, 'rougeL': 0.35744393042354217, 'rougeLsum': 0.3572235450808475} {'precision': [0.9313572645187378, 0.9072473049163818, 0.9084168076515198, 0.8732856512069702, 0.8348760604858398, 0.9630222320556641, 0.9059234261512756, 0.8986313343048096, 0.8775043487548828, 0.934466540813446, 0.8557215332984924, 0.9277669191360474, 0.8942205309867859, 0.8922761678695679, 0.8637212514877319, 0.9388770461082458, 0.9091837406158447, 0.8900796175003052, 0.8842190504074097, 0.9013169407844543, 0.928785502910614, 0.890892744064331, 0.874093234539032, 0.9505659341812134, 0.8939483761787415, 0.9039280414581299, 0.9131155014038086, 0.9033163785934448, 0.9208687543869019, 0.8964378833770752, 0.8639161586761475, 0.8713046312332153, 0.9062983989715576, 0.8219909071922302, 0.9212489724159241, 0.8666428923606873, 0.8412999510765076, 0.9319933652877808, 0.904621958732605, 0.9076036214828491, 0.9478894472122192, 0.9067267179489136, 0.8771636486053467, 0.9083446264266968, 0.9531943798065186, 0.8793061971664429, 0.938164472579956, 0.8706719279289246, 0.8644804954528809, 0.8897059559822083, 0.8828281760215759, 0.9115383625030518, 0.91633540391922, 0.9396963715553284, 0.880349338054657, 0.8276643753051758, 0.9111316204071045, 0.895056426525116, 0.8528612852096558, 0.8252553939819336, 0.901943027973175, 0.9200568795204163, 0.8871275782585144, 0.8800681829452515, 0.9240293502807617, 0.8851109147071838, 0.9072377681732178, 0.9128628969192505, 0.8788750171661377, 0.8758763670921326, 0.8863985538482666, 0.935272216796875, 0.8843488693237305, 0.9590585231781006, 0.9404681324958801, 0.8523728251457214, 0.9280033111572266, 0.8921471834182739, 0.8710130453109741, 0.8457174897193909, 0.9302701354026794, 0.9254054427146912, 0.8240306377410889, 0.8488293886184692, 0.9367972612380981, 0.8895889520645142, 0.963817834854126, 0.8521273732185364, 0.8555653095245361, 0.9248734712600708, 0.9510861039161682, 0.9034058451652527, 0.9266159534454346, 0.899020254611969, 0.8912818431854248, 0.875476598739624, 0.8760088682174683, 0.8822194933891296, 0.9576860070228577, 0.9417607188224792, 0.8980529308319092, 0.8905512094497681, 0.8223878145217896, 0.8871947526931763, 0.8550277352333069, 0.9157390594482422, 0.9351310729980469, 0.9338679909706116, 0.9357306957244873, 0.8698041439056396, 0.9458825588226318, 0.8875787258148193, 0.9226893186569214, 0.9084873795509338, 0.9031767845153809, 0.8413575291633606, 0.9051884412765503, 0.9212563037872314, 0.9257424473762512, 0.8756246566772461, 0.9098703861236572, 0.9330565929412842, 0.8468862175941467, 0.8436658382415771, 0.8713423013687134, 0.9141747951507568, 0.9028719067573547, 0.9139339923858643, 0.8888435959815979, 0.8514770269393921, 0.964047908782959, 0.8847002983093262, 0.8893139362335205, 0.8771353363990784, 0.9256271719932556, 0.9001073837280273, 0.890828549861908, 0.9001492261886597, 0.8312807083129883, 0.8391727209091187, 0.903508186340332, 0.9144467115402222, 0.8843920230865479, 0.8850013017654419, 0.9078121185302734, 0.8916842937469482, 0.8990173935890198, 0.9042267799377441, 0.8797351717948914, 0.8826735019683838, 0.9065308570861816, 0.92158043384552, 0.9249780178070068, 0.8615273237228394, 0.886644721031189, 0.8638424873352051, 0.8879755139350891, 0.8736134767532349, 0.8037328720092773, 0.9596043825149536, 0.8507586717605591, 0.8619149923324585, 0.8754242658615112, 0.9275656938552856, 0.9435687065124512, 0.9033409357070923, 0.9073748588562012, 0.9342976212501526, 0.904025673866272, 0.9346045255661011, 0.9006104469299316, 0.831936240196228, 0.94532310962677, 0.8804243803024292, 0.9510664343833923, 0.8171617984771729, 0.9181160926818848, 0.8674430847167969, 0.8857337236404419, 0.8876110315322876, 0.9156490564346313, 0.9442690014839172, 0.9267961978912354, 0.8885223865509033, 0.921027421951294, 0.9105662107467651, 0.8705645203590393, 0.8792460560798645, 0.9026457071304321, 0.9120765924453735, 0.9232033491134644, 0.8686800599098206, 0.8960968852043152, 0.8795413970947266, 0.9481821656227112, 0.8738283514976501, 0.8971706628799438, 0.8726315498352051, 0.8957221508026123, 0.8798669576644897], 'recall': [0.9302272796630859, 0.9287261962890625, 0.9065485000610352, 0.8251605033874512, 0.9167904853820801, 0.9690548777580261, 0.9300290942192078, 0.9298036098480225, 0.8875231146812439, 0.9310654997825623, 0.8712340593338013, 0.9394405484199524, 0.9150857925415039, 0.8700648546218872, 0.9138600826263428, 0.9520554542541504, 0.8925725221633911, 0.8575109243392944, 0.8862492442131042, 0.9384034872055054, 0.9415965676307678, 0.9059361219406128, 0.8944562673568726, 0.9453321695327759, 0.8760116100311279, 0.891238808631897, 0.9455497860908508, 0.8756405115127563, 0.9189672470092773, 0.9093375205993652, 0.8987616300582886, 0.8659915924072266, 0.9212859869003296, 0.8935151100158691, 0.9491246938705444, 0.895869791507721, 0.8939611315727234, 0.9089217185974121, 0.9103962182998657, 0.9418570399284363, 0.9184601306915283, 0.9500651359558105, 0.8722254037857056, 0.9463399648666382, 0.9594041109085083, 0.8817358016967773, 0.9433383941650391, 0.8941705226898193, 0.8746724724769592, 0.9291545152664185, 0.9215664863586426, 0.9152090549468994, 0.8856330513954163, 0.9463813304901123, 0.9232851266860962, 0.911466121673584, 0.928406834602356, 0.9548952579498291, 0.9117257595062256, 0.8895202279090881, 0.8971304893493652, 0.9198237657546997, 0.8839677572250366, 0.8684141635894775, 0.9645448327064514, 0.9283950924873352, 0.9024524688720703, 0.918333888053894, 0.900757908821106, 0.9042075872421265, 0.9045685529708862, 0.9251161813735962, 0.8839024305343628, 0.9336496591567993, 0.9518713355064392, 0.8761981725692749, 0.9290565252304077, 0.8920009136199951, 0.8990384936332703, 0.8939088582992554, 0.9493978023529053, 0.9238693714141846, 0.871705174446106, 0.9235796928405762, 0.9526647329330444, 0.9268357157707214, 0.9404014945030212, 0.8900461196899414, 0.8967063426971436, 0.9271611571311951, 0.9343982338905334, 0.9258354902267456, 0.950798749923706, 0.905747652053833, 0.9055850505828857, 0.8706395030021667, 0.866780698299408, 0.9103558659553528, 0.9315668344497681, 0.9535648226737976, 0.9296271204948425, 0.8768733739852905, 0.8845733404159546, 0.8780437111854553, 0.8695704340934753, 0.9317963123321533, 0.9208695888519287, 0.9198201298713684, 0.9345399737358093, 0.8943834900856018, 0.9006545543670654, 0.8999719619750977, 0.9460686445236206, 0.8927266597747803, 0.9132963418960571, 0.8926432132720947, 0.8870841264724731, 0.9320799112319946, 0.92575603723526, 0.9033358097076416, 0.9342511892318726, 0.9510111808776855, 0.8899362087249756, 0.8910053372383118, 0.8974200487136841, 0.902913510799408, 0.9164513349533081, 0.9237680435180664, 0.8992770314216614, 0.9217479825019836, 0.9344981908798218, 0.9217829704284668, 0.8887830376625061, 0.9293324947357178, 0.8374422192573547, 0.9149260520935059, 0.8866579532623291, 0.8842034339904785, 0.8907954096794128, 0.8913192749023438, 0.915145993232727, 0.8946028351783752, 0.9222776293754578, 0.8967723846435547, 0.9132214188575745, 0.9226169586181641, 0.8985501527786255, 0.9020340442657471, 0.8983869552612305, 0.8712831735610962, 0.9003643989562988, 0.9518408179283142, 0.9569646120071411, 0.8646013736724854, 0.857679009437561, 0.8787928223609924, 0.8982220888137817, 0.9433084726333618, 0.8428900837898254, 0.9627377986907959, 0.8764886856079102, 0.8916218876838684, 0.9176863431930542, 0.9439374208450317, 0.9415167570114136, 0.9100412130355835, 0.9476675391197205, 0.9545777440071106, 0.8913912773132324, 0.9250187873840332, 0.9516792893409729, 0.9242823719978333, 0.9247484803199768, 0.8876345753669739, 0.9372653961181641, 0.8617699146270752, 0.9009567499160767, 0.9064107537269592, 0.9202550053596497, 0.9315473437309265, 0.9017027020454407, 0.9258962869644165, 0.8854610919952393, 0.9031766653060913, 0.910373330116272, 0.9060086607933044, 0.8928735852241516, 0.8708488941192627, 0.869160532951355, 0.9430293440818787, 0.9406365156173706, 0.9096884727478027, 0.9446378946304321, 0.8914090394973755, 0.9505014419555664, 0.8751040101051331, 0.9319504499435425, 0.9312283992767334, 0.9142944812774658, 0.8746674656867981], 'f1': [0.930791974067688, 0.9178611040115356, 0.9074817299842834, 0.848541259765625, 0.8739179372787476, 0.9660291075706482, 0.917818009853363, 0.9139517545700073, 0.8824852705001831, 0.9327629208564758, 0.863408088684082, 0.933567225933075, 0.9045328497886658, 0.8810305595397949, 0.8880835175514221, 0.9454203248023987, 0.9008015394210815, 0.8734917640686035, 0.8852330446243286, 0.919486403465271, 0.9351471662521362, 0.8983514308929443, 0.8841575384140015, 0.9479418396949768, 0.8848891258239746, 0.8975385427474976, 0.9290496706962585, 0.8892631530761719, 0.9199169874191284, 0.9028416275978088, 0.880994439125061, 0.8686399459838867, 0.9137307405471802, 0.8562619686126709, 0.9349790811538696, 0.8810140490531921, 0.8668314218521118, 0.9203130006790161, 0.9074999094009399, 0.9244132041931152, 0.9329427480697632, 0.9278901219367981, 0.8746876120567322, 0.9269530773162842, 0.9562891721725464, 0.8805193305015564, 0.9407442808151245, 0.8822647333145142, 0.86954665184021, 0.9090023636817932, 0.9017814993858337, 0.9133700728416443, 0.9007226824760437, 0.9430270195007324, 0.9013062119483948, 0.8675462007522583, 0.9196881055831909, 0.9240080118179321, 0.8813117146492004, 0.856183648109436, 0.8995303511619568, 0.9199402928352356, 0.8855448961257935, 0.8742023706436157, 0.9438524842262268, 0.906236469745636, 0.9048387408256531, 0.915590226650238, 0.8896819353103638, 0.8898165822029114, 0.8953913450241089, 0.930166482925415, 0.8841256499290466, 0.9461835622787476, 0.946135401725769, 0.8641213178634644, 0.9285296201705933, 0.8920740485191345, 0.8848039507865906, 0.8691456913948059, 0.9397366046905518, 0.9246367812156677, 0.8471977710723877, 0.8846282958984375, 0.9446644186973572, 0.9078304767608643, 0.9519656300544739, 0.8706741333007812, 0.8756528496742249, 0.9260159134864807, 0.9426683187484741, 0.9144831895828247, 0.9385516047477722, 0.9023714065551758, 0.8983765244483948, 0.8730512857437134, 0.8713703751564026, 0.8960668444633484, 0.944445788860321, 0.947625994682312, 0.9135672450065613, 0.8836593627929688, 0.8523478507995605, 0.8825954794883728, 0.8622377514839172, 0.9236978888511658, 0.9279455542564392, 0.9267907738685608, 0.9351349472999573, 0.8819226622581482, 0.9227147102355957, 0.8937323689460754, 0.9342327117919922, 0.9005381464958191, 0.908208429813385, 0.866241991519928, 0.8960448503494263, 0.9266365170478821, 0.9257492423057556, 0.8892643451690674, 0.9218996167182922, 0.9419483542442322, 0.8678776621818542, 0.8666896820068359, 0.8841889500617981, 0.9085092544555664, 0.90961092710495, 0.9188247323036194, 0.8940299153327942, 0.8852201104164124, 0.9490430951118469, 0.9028610587120056, 0.8890483975410461, 0.9024798274040222, 0.8793293237686157, 0.9074562191963196, 0.8887382745742798, 0.8921050429344177, 0.8600096106529236, 0.864460289478302, 0.9092898368835449, 0.9044159054756165, 0.9029375910758972, 0.8908479809761047, 0.9105088114738464, 0.9068869352340698, 0.8987836837768555, 0.9031290411949158, 0.8889632225036621, 0.8769413828849792, 0.9034371376037598, 0.9364662766456604, 0.9406995177268982, 0.8630616068840027, 0.8719213604927063, 0.8712535500526428, 0.893069326877594, 0.9071242809295654, 0.8228459358215332, 0.9611685872077942, 0.863431990146637, 0.8765168190002441, 0.8960572481155396, 0.9356799721717834, 0.9425416588783264, 0.9066786766052246, 0.9270835518836975, 0.944328784942627, 0.8976640105247498, 0.9297869801521301, 0.9254409074783325, 0.8756814002990723, 0.9349225759506226, 0.8840147256851196, 0.9441154599189758, 0.8388732671737671, 0.9094554781913757, 0.8864989280700684, 0.9026644229888916, 0.9090486764907837, 0.9086223244667053, 0.9349923729896545, 0.9056572914123535, 0.8957895636558533, 0.9156693816184998, 0.9082817435264587, 0.8815779089927673, 0.8750273585319519, 0.8855867385864258, 0.9272947907447815, 0.9318383932113647, 0.8887115120887756, 0.9197273850440979, 0.8854354619979858, 0.9493404030799866, 0.8744657039642334, 0.9142298698425293, 0.9009782075881958, 0.9049130082130432, 0.8772594332695007], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.36.2)'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rougeL = []\n",
    "bert = []\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "rougescore = evaluate.load(\"rouge\")\n",
    "\n",
    "bert_score = bertscore.compute(predictions=predicted_summary, references=validate['summary'], lang = \"en\")\n",
    "rouge_score = rougescore.compute(predictions=predicted_summary, references=validate['summary'])\n",
    "print(rouge_score, bert_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e366d02-a43e-487b-9263-f4b449135081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
