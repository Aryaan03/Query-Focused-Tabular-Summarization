{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a276c4-24b9-4995-9ee4-ae5b9c71321b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from openai==0.28) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-0.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1331cd40-7ade-4c03-9b3f-023d65f185e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "train_df = datasets.load_from_disk(\"data/train\")\n",
    "test_df = datasets.load_from_disk(\"data/test\")\n",
    "validate_df = datasets.load_from_disk(\"data/validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3d1774e-35a3-47fc-af70-42ba68cd80f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item = train_df[11]\n",
    "import pandas as pd\n",
    "\n",
    "def to_pandas(item):\n",
    "  return pd.DataFrame(item['table'][\"rows\"],columns=item['table'][\"header\"])\n",
    "\n",
    "df = to_pandas(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bd176fb-cb8d-4f91-9b61-0ca391495594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 484/2000 [10:49<33:54,  1.34s/it]   \n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j4yxxcd5fck8fy04nnbwfjas` on : Limit 1000000, Used 1000073, Requested 797. Please try again in 1m15.1788s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_df))):\n\u001b[1;32m     83\u001b[0m     example \u001b[38;5;241m=\u001b[39m train_df[i]\n\u001b[0;32m---> 84\u001b[0m     decomposed_table \u001b[38;5;241m=\u001b[39m \u001b[43mdecompose_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     decomposed_tables\u001b[38;5;241m.\u001b[39mappend(decomposed_table)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Sleep for 5 minutes after every 400 entries\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[80], line 35\u001b[0m, in \u001b[0;36mdecompose_table\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     21\u001b[0m     title \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m     content_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mTable Title:\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mPlease select the relevant columns from this table to answer the user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms query.\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama-3.1-70b-versatile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful, respectful, honest, and intelligent assistant. Your task is to select relevant columns from a given table based on a user\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms natural language query. Follow these guidelines:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m1. Analyze the table structure, column headers, and all table data carefully.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m2. Interpret the user\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms query to understand their information need.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m3. Identify and select only the columns that are relevant to answering the user\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms query.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m4. If the query involves summarizing information, select all columns necessary for providing a comprehensive summary.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m5. If you cannot determine the relevant columns due to ambiguity or lack of clarity in the query, select all the columns to ensure no relevant data is omitted.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m6. Provide a list of the relevant column names. Do not include any other information in the output.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m7. Be precise and avoid selecting irrelevant columns.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_text\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     full_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m completion:\n",
      "File \u001b[0;32m/blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages/groq/resources/chat/completions.py:289\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages/groq/_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1224\u001b[0m     )\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages/groq/_base_client.py:920\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    913\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    919\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/bonniejdorr/y.khan/.conda/envs/hf-llm/lib/python3.10/site-packages/groq/_base_client.py:1018\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1017\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1021\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1022\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1026\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j4yxxcd5fck8fy04nnbwfjas` on : Limit 1000000, Used 1000073, Requested 797. Please try again in 1m15.1788s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "client = Groq(api_key = your_api_key)\n",
    "\n",
    "\n",
    "def normalize_column_name(name):\n",
    "    return name.replace(\" \", \"\").lower()\n",
    "\n",
    "def decompose_table(example):\n",
    "    table = to_pandas(example)\n",
    "    table_markdown = table.to_markdown()\n",
    "    query = example['query']\n",
    "    title = example['table']['title']\n",
    "    \n",
    "    content_text = f\"\"\"Table Title:\n",
    "{title}\n",
    "\n",
    "Table:\n",
    "{table_markdown}\n",
    "\n",
    "User Query:\n",
    "{query}\n",
    "\n",
    "Please select the relevant columns from this table to answer the user's query.\n",
    "\"\"\"\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful, respectful, honest, and intelligent assistant. Your task is to select relevant columns from a given table based on a user's natural language query. Follow these guidelines:\\n1. Analyze the table structure, column headers, and all table data carefully.\\n2. Interpret the user's query to understand their information need.\\n3. Identify and select only the columns that are relevant to answering the user's query.\\n4. If the query involves summarizing information, select all columns necessary for providing a comprehensive summary.\\n5. If you cannot determine the relevant columns due to ambiguity or lack of clarity in the query, select all the columns to ensure no relevant data is omitted.\\n6. Provide a list of the relevant column names. Do not include any other information in the output.\\n7. Be precise and avoid selecting irrelevant columns.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content_text\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "\n",
    "    for chunk in completion:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            full_response += chunk.choices[0].delta.content.strip()\n",
    "\n",
    "    # Parse and normalize the response to get the list of relevant columns\n",
    "    relevant_columns = [col.strip() for col in full_response.split(',') if col.strip()]\n",
    "    relevant_columns_normalized = [normalize_column_name(col) for col in relevant_columns]\n",
    "\n",
    "    # Normalize the table columns\n",
    "    table_columns_normalized = {normalize_column_name(col): col for col in table.columns}\n",
    "\n",
    "    # Map normalized column names back to original column names\n",
    "    selected_columns = [table_columns_normalized[col] for col in relevant_columns_normalized if col in table_columns_normalized]\n",
    "\n",
    "    # Check if the number of relevant columns is less than 3\n",
    "    if len(selected_columns) < 3:\n",
    "        selected_columns = table.columns.tolist()  # Keep all columns\n",
    "\n",
    "    # Create the decomposed table\n",
    "    decomposed_table = table[selected_columns]\n",
    "    return decomposed_table\n",
    "\n",
    "# List to store decomposed tables\n",
    "decomposed_tables = []\n",
    "\n",
    "# Process all examples and store decomposed tables\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    example = train_df[i]\n",
    "    decomposed_table = decompose_table(example)\n",
    "    decomposed_tables.append(decomposed_table)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d46c966-0067-4952-bee0-d4b890a6ad65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decomposed_tables_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9901c6bf-b5c9-42ba-8bfa-e3e974dffb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decomposed_tables_validate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ddf2dd0-915b-4f8f-b5ec-845dfb7c1953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:13<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(131, len(validate_df))):\n",
    "    example = validate_df[i]\n",
    "    decomposed_table = decompose_table(example)\n",
    "    decomposed_tables_validate.append(decomposed_table)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a561f19a-2b56-49fd-923d-1d0112cc0918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 3483.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_ids': [4], 'summary': \"Tim Reeves and Dipash Chauhan had a mixed performance in the 2010 Isle Of Man TT. On the 29th of May, their race was cancelled, leaving them without a time. On the 31st, there wasn't a time for them. On the 1st, they recorded a time of 20'59.60, good for 107.834 mph. The following day, they posted a time of 20'45.81, a slight improvement at 109.028 mph. On the 3rd, they again improved their time to 20'26.35 and 110.758 mph. On the 4th, however, their time regressed to 37'03.92, a much slower 61.076 mph. Overall, it was a performance of ups and downs, with a few improvements from the start of the race to the end.\", 'query': 'Summarize the performance of Tim Reeves and Dipash Chauhan in 2010 Isle Of Man TT.', 'table': {'header': ['Rank', 'Rider', 'Sat 29 May', 'Mon 31 May', 'Tues 1 June', 'Wed 2 June', 'Thurs 3 June', 'Fri 4 June'], 'rows': [['2', 'Klaus Klaffenböck / Dan Sayle 600Cc Lcr Honda', 'Cancelled No Time', \"20'15.35 111.761 Mph\", \"20'05.79 112.647 Mph\", \"19'55.92 113.576 Mph\", \"19'50.47 114.096 Mph\", \"19'56.64 113.508 Mph\"], ['3', 'John Holden / Andrew Winkle 600Cc Lcr Suzuki', 'Cancelled No Time', \"20'17.36 111.576 Mph\", \"20'09.86 112.267 Mph\", \"20'04.82 112.737 Mph\", \"20'15.90 111.710 Mph\", \"19'59.43 113.224 Mph\"], ['4', 'Simon Neary / Paul Knapton 600Cc Honda', 'Cancelled No Time', \"20'24.08 110.964 Mph\", \"20'05.64 112.661 Mph\", \"20'11.98 112.071 Mph\", \"20'00.19 113.172 Mph\", \"20'01.41 113.058 Mph\"], ['5', 'Conrad Harrison / Kerry Williams 600Cc Honda', 'Cancelled No Time', \"20'50.30 108.636 Mph\", \"20'27.78 110.629 Mph\", \"20'25.77 110.810 Mph\", \"20'13.17 111.962 Mph\", \"20'29.39 110.484 Mph\"], ['6', 'Tim Reeves / Dipash Chauhan 600Cc Honda', 'Cancelled No Time', '-- No Time', \"20'59.60 107.834 Mph\", \"20'45.81 109.028 Mph\", \"20'26.35 110.758 Mph\", \"37'03.92 61.076 Mph\"], ['7', 'Gary Bryan / Gary Partridge 600Cc Honda', 'Cancelled No Time', \"21'21.24 106.013 Mph\", \"21'09.41 107.001 Mph\", \"20'47.90 108.845 Mph\", \"20'27.35 110.668 Mph\", \"20'40.91 109.459 Mph\"], ['8', 'Roy Hanks / Dave Wells 600Cc Suzuki', 'Cancelled No Time', \"21'36.43 104.771 Mph\", \"21'05.27 107.351 Mph\", \"20'50.62 108.608 Mph\", \"20'27.93 110.615 Mph\", '-- No Time'], ['9', 'Tony Elmer / Darren Marshall 600Cc Ireson Yamaha', 'Cancelled No Time', \"21'35.11 108.877 Mph\", \"21'02.66 107.573 Mph\", \"20'43.24 109.253 Mph\", \"20'28.72 110.554 Mph\", \"20'39.74 109.562 Mph\"]], 'table_id': '26cdae7c-7139-4c25-8d6c-7b0746dd33a8', 'title': '2010 Isle Of Man Tt'}, 'example_id': '25caf8c2-9dcc-463e-84cc-445a2255523d'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_df[i]['table']['header'] = decomposed_tables[i].columns.tolist()\n",
    "    train_df[i]['table']['rows'] = decomposed_tables[i].values.tolist()\n",
    "\n",
    "# Save the modified dataset back to disk\n",
    "train_df.save_to_disk(\"data/decomposed_train\")\n",
    "\n",
    "# Print a sample to verify\n",
    "print(train_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b0b4156b-7dbd-4125-a38f-8a44de6dc632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 646.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def dataframe_to_dict(df):\n",
    "    return {\n",
    "        'header': list(df.columns),\n",
    "        'rows': df.values.tolist()\n",
    "    }\n",
    "\n",
    "# Convert all DataFrames to dictionary format\n",
    "decomposed_dicts = [dataframe_to_dict(df) for df in decomposed_tables_validate]\n",
    "\n",
    "# Function to replace the table with the decomposed one\n",
    "def replace_table(example, idx):\n",
    "    example['table'] = decomposed_dicts[idx]\n",
    "    return example\n",
    "\n",
    "# Apply the replacement\n",
    "decomposed_validate = validate_df.map(replace_table, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eb966fca-5ef8-43ed-9566-2d8e471fb080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 500/500 [00:01<00:00, 441.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "decomposed_test.save_to_disk(\"data/decomposed_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11146d1a-f828-47a8-b760-1d3a6f9249d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name, \n",
      "Color, \n",
      "Price"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful, respectful, honest and intelligent assistant. Your task is to select relevant columns from a given table based on a user's natural language query. Follow these guidelines:\\n1. Analyze the table structure and column headers carefully.\\n2. Interpret the user's query to understand their information need.\\n3. Identify and select only the columns that are relevant to answering the user's query.\\n4. If the query involves summarizing information, select all columns necessary for providing a comprehensive summary.\\n5. If you cannot determine the relevant columns due to ambiguity or lack of clarity in the query, select all the columns to ensure no relevant data is omitted.\\n6. Provide a list of the relevant column names. Do not include any other information in the output\\n7. Be precise and avoid selecting irrelevant columns..\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Table:\\n| Product Name | Category | Price | Stock | Manufacturer | Color | Weight (kg) | Release Date |\\n\\nUser Query: \\\"What are the available blue products under $50?\\\"\\n\\nPlease select the relevant columns from this table to answer the user's query.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890aa54-1b81-4eba-841e-e7d5d19c68bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
