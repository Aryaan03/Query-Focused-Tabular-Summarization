{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5897e4e7-9bcc-441c-9be6-9ee68bd34549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -entence-transformers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -nstructured (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -uggingface-hub (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow in /home/jgarciga/.local/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (4.25.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (3.0.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from tensorflow) (1.24.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: rich in /home/jgarciga/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/jgarciga/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /home/jgarciga/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jgarciga/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jgarciga/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jgarciga/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -entence-transformers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -nstructured (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -uggingface-hub (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -entence-transformers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -nstructured (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -uggingface-hub (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: rouge-score in /home/jgarciga/.local/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /home/jgarciga/.local/lib/python3.10/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from rouge-score) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from nltk->rouge-score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from nltk->rouge-score) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /apps/jupyter/6.5.4/lib/python3.10/site-packages (from nltk->rouge-score) (4.66.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -entence-transformers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -nstructured (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -okenizers (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -uggingface-hub (/apps/jupyter/6.5.4/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c043447-4924-4dec-a4cb-f4b23c172aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "huggingface_token = \"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\"\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "train_df = load_dataset(\"yale-nlp/QTSumm\", token = huggingface_token, split='train')\n",
    "test_df = load_dataset(\"yale-nlp/QTSumm\", token = huggingface_token, split='test')\n",
    "validate_df = load_dataset(\"yale-nlp/QTSumm\", token = huggingface_token, split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c39b834a-6e71-4f2a-9c76-3edfebcb88e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def tokenization(examples):\n",
    "    inputs = [f\"query:  {query} header: {' '.join(map(str, entry.get('header', [])))} rows: {' '.join(map(str, entry.get('rows', [])))} title: {' '.join(map(str, entry.get('title', [])))}\"\n",
    "    for query, entry in zip(examples['query'], examples['table'])]\n",
    "    res = tokenizer(inputs, text_target=examples['summary'], truncation = True, padding = True)\n",
    "    return res\n",
    "\n",
    "tokenized_dataset_train = train_df.map(tokenization, batched=True)\n",
    "tokenized_dataset_test = test_df.map(tokenization, batched=True)\n",
    "tokenized_dataset_validate = validate_df.map(tokenization, batched=True)\n",
    "\n",
    "processed_data_train = tokenized_dataset_train.remove_columns(['table','summary', 'row_ids', 'example_id', 'query'])\n",
    "processed_data_test = tokenized_dataset_test.remove_columns(['table','summary', 'row_ids', 'example_id', 'query'])\n",
    "processed_data_validate = tokenized_dataset_validate.remove_columns(['table','summary', 'row_ids', 'example_id', 'query'])\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aed3aba-2da8-4690-a211-9eba7322cb25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 22:34:10.640338: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 22:34:13.871752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1040/1040 34:02, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.148242</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.018955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.599507</td>\n",
       "      <td>0.118695</td>\n",
       "      <td>0.044411</td>\n",
       "      <td>0.089383</td>\n",
       "      <td>0.089368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.975691</td>\n",
       "      <td>0.269453</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>0.228142</td>\n",
       "      <td>0.228104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.862850</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>0.166756</td>\n",
       "      <td>0.249949</td>\n",
       "      <td>0.249814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.818485</td>\n",
       "      <td>0.301852</td>\n",
       "      <td>0.168822</td>\n",
       "      <td>0.252331</td>\n",
       "      <td>0.252311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.796278</td>\n",
       "      <td>0.306688</td>\n",
       "      <td>0.172871</td>\n",
       "      <td>0.256442</td>\n",
       "      <td>0.256324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.782572</td>\n",
       "      <td>0.307781</td>\n",
       "      <td>0.173716</td>\n",
       "      <td>0.258493</td>\n",
       "      <td>0.258276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.773315</td>\n",
       "      <td>0.307163</td>\n",
       "      <td>0.174570</td>\n",
       "      <td>0.258990</td>\n",
       "      <td>0.258691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.765791</td>\n",
       "      <td>0.309006</td>\n",
       "      <td>0.175789</td>\n",
       "      <td>0.260155</td>\n",
       "      <td>0.259896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.759892</td>\n",
       "      <td>0.307511</td>\n",
       "      <td>0.174005</td>\n",
       "      <td>0.259125</td>\n",
       "      <td>0.258862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.755264</td>\n",
       "      <td>0.309316</td>\n",
       "      <td>0.176430</td>\n",
       "      <td>0.261205</td>\n",
       "      <td>0.260812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.751509</td>\n",
       "      <td>0.310146</td>\n",
       "      <td>0.177567</td>\n",
       "      <td>0.261990</td>\n",
       "      <td>0.261747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.749054</td>\n",
       "      <td>0.310016</td>\n",
       "      <td>0.177412</td>\n",
       "      <td>0.262472</td>\n",
       "      <td>0.262252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.746698</td>\n",
       "      <td>0.311868</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.264048</td>\n",
       "      <td>0.263837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.744954</td>\n",
       "      <td>0.309403</td>\n",
       "      <td>0.177351</td>\n",
       "      <td>0.262458</td>\n",
       "      <td>0.262207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.743177</td>\n",
       "      <td>0.311079</td>\n",
       "      <td>0.178762</td>\n",
       "      <td>0.263909</td>\n",
       "      <td>0.263677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.742085</td>\n",
       "      <td>0.310508</td>\n",
       "      <td>0.178254</td>\n",
       "      <td>0.262395</td>\n",
       "      <td>0.262166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.741304</td>\n",
       "      <td>0.310699</td>\n",
       "      <td>0.178630</td>\n",
       "      <td>0.263330</td>\n",
       "      <td>0.263059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.867200</td>\n",
       "      <td>0.740893</td>\n",
       "      <td>0.310887</td>\n",
       "      <td>0.178593</td>\n",
       "      <td>0.263437</td>\n",
       "      <td>0.263169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.740804</td>\n",
       "      <td>0.311220</td>\n",
       "      <td>0.178722</td>\n",
       "      <td>0.263816</td>\n",
       "      <td>0.263498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./train_weights/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./train_weights/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1040, training_loss=1.749329554117643, metrics={'train_runtime': 2076.1865, 'train_samples_per_second': 47.982, 'train_steps_per_second': 0.501, 'total_flos': 6.821552745086976e+16, 'train_loss': 1.749329554117643, 'epoch': 20.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    for label in labels:\n",
    "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    rouge = evaluate.load('rouge')\n",
    "    results = rouge.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "\n",
    "    return results\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model= model)\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"./train_weights\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=20,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        predict_with_generate=True,\n",
    "        overwrite_output_dir= True\n",
    "    )\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "        model,\n",
    "        train_args,\n",
    "        train_dataset=processed_data_train,\n",
    "        eval_dataset=processed_data_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=metric_fn\n",
    "    )\n",
    "    \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6d3ad5-0dd5-49b9-8ee9-d8122a33cb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./train_weights/checkpoint-1000\", device_map='auto')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./train_weights/checkpoint-1000\")\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130b2a61-559f-45ae-ace1-6b75729b78a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_text(examples):\n",
    "    inputs = [f\"query:  {query} header: {' '.join(map(str, entry.get('header', [])))} rows: {' '.join(map(str, entry.get('rows', [])))} title: {' '.join(map(str, entry.get('title', [])))}\"\n",
    "    for query, entry in zip(examples['query'], examples['table'])]\n",
    "    examples['text'] = inputs\n",
    "    return examples\n",
    "\n",
    "tester = test_df.map(create_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddb5c81-e186-4d50-a0d9-c892b546b0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['summary', 'example_id', 'query', 'row_ids', 'table', 'text'],\n",
       "    num_rows: 1078\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01fd5a9-953a-4f22-82d0-006901b3e0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "vals = []\n",
    "for out in pipe(\n",
    "        KeyDataset(tester, \"text\"),\n",
    "        do_sample=False,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id, ):\n",
    "    vals.append(out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a276af-afa9-425d-9a6e-342cc10374ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'The team that use KTM-VMC equipment is Danil Willemsen / Kenny Van Gaalen, who is driving the Zabel - Wsp team. He is a driver with a total of 452 points and a passenger with 385 points. Jan Hendrickx / Tim Smeuninx also use the KTM - VMC equipment, with 222 points and 369 points.'}]\n",
      "query:  Summarize the team(s) that are using KTM-VMC equipment. header: Position Driver / Passenger Equipment Bike No Points rows: ['1', 'Daniãl Willemsen / Kenny Van Gaalen', 'Zabel - Wsp', '1', '452'] ['2', 'Etienne Bax / Kaspars Stupelis', 'Zabel - Wsp', '5', '447'] ['3', 'Ben Adriaenssen / Sven Verbrugge', 'Ktm - Wsp', '6', '385'] ['4', 'Joris Hendrickx / Kaspars Liepins', 'Ktm - Vmc', '222', '369'] ['5', 'Jan Hendrickx / Tim Smeuninx', 'Zabel - Vmc', '3', '369'] ['6', 'Valentin Giraud / Nicolas Musset', 'Ktm - Wht', '138', '334'] ['7', 'Vaclav Rozehnal / Marek Rozehnal', 'Zabel - Vmc', '11', '240'] ['8', 'Marcel Willemsen / Gertie Eggink', 'Zabel - Mefo', '21', '223'] ['9', 'Maris Rupeiks / Elvijs Mucenieks', 'Zabel - Wsp', '4', '194'] title: S i d e c a r c r o s s   W o r l d   C h a m p i o n s h i p\n",
      "The team that is using KTM-VMC equipment in the Sidecarcross World Championship is in fourth place. Driver Joris Hendrickx and Passenger Kaspars Liepins are seated in this position with a total of 369 points within the championship.\n"
     ]
    }
   ],
   "source": [
    "i = 482\n",
    "print(pipe(tester['text'][i]))\n",
    "print(tester['text'][i])\n",
    "print(tester['summary'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739ff8a9-5b06-48da-9093-45352aaa38a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Roberts from Maryland and Samuel Alito from New Zersey   were appointed by a President Bush.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d8c606-08ba-4836-afc4-9c2e8e5f6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "## Jairo changes with KFold\n",
    "all_data = datasets.concatenate_datasets([train_df, test_df, validate_df]) # combine for k-fald, consider only combining train and validate\n",
    "all_data = all_data.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dcfb89e-3e2c-484a-bc65-bec23a23376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def k_fold_split(dataset, num_folds=5):\n",
    "    fold_size = len(dataset) // num_folds\n",
    "    folds = []\n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if i < num_folds - 1 else len(dataset)\n",
    "        folds.append(dataset.select(range(start, end)))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5801103-fe71-459e-8dfb-add62cb7e309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5689/5689 [00:07<00:00, 731.67 examples/s]\n",
      "Map: 100%|██████████| 1422/1422 [00:01<00:00, 721.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 41:16, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.532276</td>\n",
       "      <td>0.315868</td>\n",
       "      <td>0.187394</td>\n",
       "      <td>0.272763</td>\n",
       "      <td>0.272940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530985</td>\n",
       "      <td>0.315770</td>\n",
       "      <td>0.188232</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.272526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.531563</td>\n",
       "      <td>0.315974</td>\n",
       "      <td>0.187663</td>\n",
       "      <td>0.272940</td>\n",
       "      <td>0.273156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530249</td>\n",
       "      <td>0.314669</td>\n",
       "      <td>0.187952</td>\n",
       "      <td>0.271384</td>\n",
       "      <td>0.271585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530288</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.189157</td>\n",
       "      <td>0.273631</td>\n",
       "      <td>0.273853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.529823</td>\n",
       "      <td>0.315698</td>\n",
       "      <td>0.187911</td>\n",
       "      <td>0.272491</td>\n",
       "      <td>0.272746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.529345</td>\n",
       "      <td>0.316345</td>\n",
       "      <td>0.188757</td>\n",
       "      <td>0.273586</td>\n",
       "      <td>0.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.528345</td>\n",
       "      <td>0.316942</td>\n",
       "      <td>0.189323</td>\n",
       "      <td>0.274038</td>\n",
       "      <td>0.274292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.528366</td>\n",
       "      <td>0.316157</td>\n",
       "      <td>0.190025</td>\n",
       "      <td>0.273960</td>\n",
       "      <td>0.274204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.527838</td>\n",
       "      <td>0.316732</td>\n",
       "      <td>0.189278</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.274474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.527631</td>\n",
       "      <td>0.315990</td>\n",
       "      <td>0.188761</td>\n",
       "      <td>0.273637</td>\n",
       "      <td>0.273912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.527184</td>\n",
       "      <td>0.315717</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>0.273182</td>\n",
       "      <td>0.273423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.527262</td>\n",
       "      <td>0.315772</td>\n",
       "      <td>0.188787</td>\n",
       "      <td>0.273334</td>\n",
       "      <td>0.273563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.526843</td>\n",
       "      <td>0.315041</td>\n",
       "      <td>0.187532</td>\n",
       "      <td>0.272845</td>\n",
       "      <td>0.273062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.526542</td>\n",
       "      <td>0.316244</td>\n",
       "      <td>0.188978</td>\n",
       "      <td>0.274049</td>\n",
       "      <td>0.274263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>0.526447</td>\n",
       "      <td>0.316323</td>\n",
       "      <td>0.189802</td>\n",
       "      <td>0.274556</td>\n",
       "      <td>0.274844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.526361</td>\n",
       "      <td>0.316180</td>\n",
       "      <td>0.189139</td>\n",
       "      <td>0.274091</td>\n",
       "      <td>0.274452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.526277</td>\n",
       "      <td>0.316406</td>\n",
       "      <td>0.189185</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.274457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.526252</td>\n",
       "      <td>0.315619</td>\n",
       "      <td>0.188445</td>\n",
       "      <td>0.273649</td>\n",
       "      <td>0.273821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.526266</td>\n",
       "      <td>0.315386</td>\n",
       "      <td>0.188257</td>\n",
       "      <td>0.273459</td>\n",
       "      <td>0.273638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./train_weights/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./train_weights/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5689/5689 [00:07<00:00, 772.14 examples/s]\n",
      "Map: 100%|██████████| 1422/1422 [00:01<00:00, 790.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 41:51, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572450</td>\n",
       "      <td>0.318869</td>\n",
       "      <td>0.193607</td>\n",
       "      <td>0.273363</td>\n",
       "      <td>0.273038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572180</td>\n",
       "      <td>0.318907</td>\n",
       "      <td>0.193385</td>\n",
       "      <td>0.273033</td>\n",
       "      <td>0.272921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572722</td>\n",
       "      <td>0.319371</td>\n",
       "      <td>0.194746</td>\n",
       "      <td>0.273847</td>\n",
       "      <td>0.273662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.573061</td>\n",
       "      <td>0.319074</td>\n",
       "      <td>0.193481</td>\n",
       "      <td>0.273596</td>\n",
       "      <td>0.273480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572866</td>\n",
       "      <td>0.317890</td>\n",
       "      <td>0.193186</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.272162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572927</td>\n",
       "      <td>0.318614</td>\n",
       "      <td>0.193231</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.272780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572826</td>\n",
       "      <td>0.318621</td>\n",
       "      <td>0.193432</td>\n",
       "      <td>0.273326</td>\n",
       "      <td>0.273168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572529</td>\n",
       "      <td>0.318725</td>\n",
       "      <td>0.193517</td>\n",
       "      <td>0.273554</td>\n",
       "      <td>0.273301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.572627</td>\n",
       "      <td>0.318449</td>\n",
       "      <td>0.193905</td>\n",
       "      <td>0.273447</td>\n",
       "      <td>0.273314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.572231</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.193778</td>\n",
       "      <td>0.273489</td>\n",
       "      <td>0.273376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>0.319273</td>\n",
       "      <td>0.194267</td>\n",
       "      <td>0.274353</td>\n",
       "      <td>0.274174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.572182</td>\n",
       "      <td>0.318290</td>\n",
       "      <td>0.193637</td>\n",
       "      <td>0.273799</td>\n",
       "      <td>0.273566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.571940</td>\n",
       "      <td>0.319441</td>\n",
       "      <td>0.194875</td>\n",
       "      <td>0.274786</td>\n",
       "      <td>0.274551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.571796</td>\n",
       "      <td>0.318659</td>\n",
       "      <td>0.193538</td>\n",
       "      <td>0.273755</td>\n",
       "      <td>0.273645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.571783</td>\n",
       "      <td>0.319498</td>\n",
       "      <td>0.194399</td>\n",
       "      <td>0.274859</td>\n",
       "      <td>0.274697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.571696</td>\n",
       "      <td>0.318990</td>\n",
       "      <td>0.194237</td>\n",
       "      <td>0.274261</td>\n",
       "      <td>0.274081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.571568</td>\n",
       "      <td>0.319671</td>\n",
       "      <td>0.194811</td>\n",
       "      <td>0.274829</td>\n",
       "      <td>0.274734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.571649</td>\n",
       "      <td>0.319478</td>\n",
       "      <td>0.194922</td>\n",
       "      <td>0.274883</td>\n",
       "      <td>0.274705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.571591</td>\n",
       "      <td>0.319471</td>\n",
       "      <td>0.194731</td>\n",
       "      <td>0.274860</td>\n",
       "      <td>0.274812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.571623</td>\n",
       "      <td>0.319425</td>\n",
       "      <td>0.194823</td>\n",
       "      <td>0.274654</td>\n",
       "      <td>0.274628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./train_weights/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./train_weights/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5689/5689 [00:07<00:00, 719.37 examples/s]\n",
      "Map: 100%|██████████| 1422/1422 [00:02<00:00, 703.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='696' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 696/1200 23:31 < 17:05, 0.49 it/s, Epoch 11.58/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.492298</td>\n",
       "      <td>0.317293</td>\n",
       "      <td>0.196126</td>\n",
       "      <td>0.279054</td>\n",
       "      <td>0.278926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493016</td>\n",
       "      <td>0.317078</td>\n",
       "      <td>0.195439</td>\n",
       "      <td>0.278579</td>\n",
       "      <td>0.278599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493376</td>\n",
       "      <td>0.317407</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>0.279375</td>\n",
       "      <td>0.279428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493702</td>\n",
       "      <td>0.317086</td>\n",
       "      <td>0.195194</td>\n",
       "      <td>0.278686</td>\n",
       "      <td>0.278737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493840</td>\n",
       "      <td>0.316595</td>\n",
       "      <td>0.194045</td>\n",
       "      <td>0.277695</td>\n",
       "      <td>0.277621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494479</td>\n",
       "      <td>0.317811</td>\n",
       "      <td>0.195382</td>\n",
       "      <td>0.279140</td>\n",
       "      <td>0.279132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494270</td>\n",
       "      <td>0.317508</td>\n",
       "      <td>0.195015</td>\n",
       "      <td>0.278487</td>\n",
       "      <td>0.278529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494261</td>\n",
       "      <td>0.318622</td>\n",
       "      <td>0.195949</td>\n",
       "      <td>0.279652</td>\n",
       "      <td>0.279708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.494880</td>\n",
       "      <td>0.317730</td>\n",
       "      <td>0.195644</td>\n",
       "      <td>0.279126</td>\n",
       "      <td>0.279227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.494495</td>\n",
       "      <td>0.318251</td>\n",
       "      <td>0.195748</td>\n",
       "      <td>0.279498</td>\n",
       "      <td>0.279507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.494914</td>\n",
       "      <td>0.317760</td>\n",
       "      <td>0.196047</td>\n",
       "      <td>0.279743</td>\n",
       "      <td>0.279717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./train_weights/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "folds = k_fold_split(all_data, num_folds=5)\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    val_fold = folds[i]\n",
    "    train_folds = [folds[j] for j in range(len(folds)) if j != i]\n",
    "    train_dataset = datasets.concatenate_datasets(train_folds)\n",
    "\n",
    "    tokenized_train = train_dataset.map(tokenization, batched=True)\n",
    "    tokenized_val = val_fold.map(tokenization, batched=True)\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    processed_train = tokenized_train.remove_columns(['table', 'summary', 'row_ids', 'example_id', 'query'])\n",
    "    processed_val = tokenized_val.remove_columns(['table', 'summary', 'row_ids', 'example_id', 'query'])\n",
    "\n",
    "    # Update your trainer's train_dataset and eval_dataset\n",
    "    trainer.train_dataset = processed_train\n",
    "    trainer.eval_dataset = processed_val\n",
    "\n",
    "    # Train your model\n",
    "    trainer.train()\n",
    "    trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f49620-061d-4c9b-9472-febcb3ecb6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jairo_QTSUMM",
   "language": "python",
   "name": "jairo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
